{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'H:\\AI mini Project\\Movie classifications\\test_kaggle.csv\\test_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_index</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "      <th>date_published</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>production_company</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>budget</th>\n",
       "      <th>usa_gross_income</th>\n",
       "      <th>worlwide_gross_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Pohwasogeuro</td>\n",
       "      <td>Pohwasogeuro</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>Action, Drama, War</td>\n",
       "      <td>120</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Korean, English</td>\n",
       "      <td>John H. Lee</td>\n",
       "      <td>Man-Hee Lee, Dong-Woo Kim</td>\n",
       "      <td>Taewon Entertainment</td>\n",
       "      <td>Seung-Won Cha, Sang-Woo Kwon, Seung-Hyun Choi,...</td>\n",
       "      <td>The story of student-soldiers trying to protec...</td>\n",
       "      <td>$ 10000000</td>\n",
       "      <td>$ 176638</td>\n",
       "      <td>$ 20967660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Babadook</td>\n",
       "      <td>The Babadook</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Drama, Horror</td>\n",
       "      <td>94</td>\n",
       "      <td>Australia, Canada</td>\n",
       "      <td>English</td>\n",
       "      <td>Jennifer Kent</td>\n",
       "      <td>Jennifer Kent</td>\n",
       "      <td>Screen Australia</td>\n",
       "      <td>Essie Davis, Noah Wiseman, Hayley McElhinney, ...</td>\n",
       "      <td>A single mother and her child fall into a deep...</td>\n",
       "      <td>$ 2000000</td>\n",
       "      <td>$ 964413</td>\n",
       "      <td>$ 10312540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title_index         title original_title  year date_published  \\\n",
       "11           11  Pohwasogeuro   Pohwasogeuro  2010     2010-06-16   \n",
       "40           40      Babadook   The Babadook  2014     2015-07-15   \n",
       "\n",
       "                 genre  duration            country         language  \\\n",
       "11  Action, Drama, War       120        South Korea  Korean, English   \n",
       "40       Drama, Horror        94  Australia, Canada          English   \n",
       "\n",
       "         director                     writer    production_company  \\\n",
       "11    John H. Lee  Man-Hee Lee, Dong-Woo Kim  Taewon Entertainment   \n",
       "40  Jennifer Kent              Jennifer Kent      Screen Australia   \n",
       "\n",
       "                                               actors  \\\n",
       "11  Seung-Won Cha, Sang-Woo Kwon, Seung-Hyun Choi,...   \n",
       "40  Essie Davis, Noah Wiseman, Hayley McElhinney, ...   \n",
       "\n",
       "                                          description      budget  \\\n",
       "11  The story of student-soldiers trying to protec...  $ 10000000   \n",
       "40  A single mother and her child fall into a deep...   $ 2000000   \n",
       "\n",
       "   usa_gross_income worlwide_gross_income  \n",
       "11         $ 176638            $ 20967660  \n",
       "40         $ 964413            $ 10312540  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('0')\n",
    "# Assuming df is your DataFrame\n",
    "features = df.drop(['usa_gross_income','worlwide_gross_income'], axis=1)\n",
    "targets = df[['usa_gross_income','worlwide_gross_income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_preprocessed = np.vectorize(lambda x: float(re.sub(r'\\D', '', x)))(y_train)\n",
    "y_test_preprocessed = np.vectorize(lambda x: float(re.sub(r'\\D', '', x)))(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1528, 15) (382, 15) (1528, 2) (382, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train_preprocessed.shape, y_test_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to numpy arrays\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\origi\\AppData\\Local\\Temp\\ipykernel_6332\\1239337700.py:1: RuntimeWarning: invalid value encountered in cast\n",
      "  y_train_preprocessed = y_train_preprocessed.astype('int')\n"
     ]
    }
   ],
   "source": [
    "y_train_preprocessed = y_train_preprocessed.astype('int')\n",
    "y_train_preprocessed = y_train_preprocessed.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove single quotes\n",
    "X_train = np.array([str(i).replace(\"'\", \"\") for i in X_train])\n",
    "X_test = np.array([str(i).replace(\"'\", \"\") for i in X_test])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   205569,    205569],\n",
       "       [ 23637265,  80743363],\n",
       "       [113804681, 222104681],\n",
       "       ...,\n",
       "       [ 36144000,  36179290],\n",
       "       [ 19889299,  19889299],\n",
       "       [ 11901145,  18096691]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_preprocessed\n",
    "y_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_data = [str(item).lower() for item in X_train]\n",
    "tokenizer.fit_on_texts(lower_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[10956 Hot Fuzz Hot Fuzz 2007 2007-08-24 Action, Comedy, Mystery\\n 121 UK, France English Edgar Wright Edgar Wright, Simon Pegg\\n StudioCanal\\n Simon Pegg, Martin Freeman, Bill Nighy, Robert Popper, Joe Cornish, Chris Waitt, Eric Mason, Billie Whitelaw, Nick Frost, Peter Wight, Julia Deakin, Tom Strode Walton, Troy Woollan, Rory Lowings, Bill Bailey\\n A skilled London police officer is transferred to a small town with a dark secret.\\n GBP 8000000]'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10956 hot fuzz hot fuzz 2007 2007-08-24 action, comedy, mystery\n",
      " 121 uk, france english edgar wright edgar wright, simon pegg\n",
      " studiocanal\n",
      " simon pegg, martin freeman, bill nighy, robert popper, joe cornish, chris waitt, eric mason, billie whitelaw, nick frost, peter wight, julia deakin, tom strode walton, troy woollan, rory lowings, bill bailey\n",
      " a skilled london police officer is transferred to a small town with a dark secret.\n",
      " gbp 8000000]\n"
     ]
    }
   ],
   "source": [
    "print(lower_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'the': 2,\n",
       " 'english': 3,\n",
       " 'to': 4,\n",
       " 'of': 5,\n",
       " 'usa': 6,\n",
       " 'and': 7,\n",
       " 'in': 8,\n",
       " 'drama': 9,\n",
       " 'his': 10,\n",
       " 'comedy': 11,\n",
       " 'michael': 12,\n",
       " 'john': 13,\n",
       " 'david': 14,\n",
       " 'is': 15,\n",
       " 'with': 16,\n",
       " 'an': 17,\n",
       " 'pictures': 18,\n",
       " 'her': 19,\n",
       " 'james': 20,\n",
       " 'action': 21,\n",
       " 'on': 22,\n",
       " 'robert': 23,\n",
       " 'crime': 24,\n",
       " 'for': 25,\n",
       " 'their': 26,\n",
       " 'adventure': 27,\n",
       " 'who': 28,\n",
       " 'romance': 29,\n",
       " 'he': 30,\n",
       " 'uk': 31,\n",
       " 'richard': 32,\n",
       " 'paul': 33,\n",
       " 'peter': 34,\n",
       " 'by': 35,\n",
       " 'when': 36,\n",
       " 'from': 37,\n",
       " 'thriller': 38,\n",
       " 'tom': 39,\n",
       " 'that': 40,\n",
       " '01': 41,\n",
       " '09': 42,\n",
       " '04': 43,\n",
       " 'family': 44,\n",
       " 'new': 45,\n",
       " 'young': 46,\n",
       " '10': 47,\n",
       " 'j': 48,\n",
       " '03': 49,\n",
       " 'after': 50,\n",
       " 'films': 51,\n",
       " '05': 52,\n",
       " 'scott': 53,\n",
       " 'french': 54,\n",
       " '11': 55,\n",
       " 'mark': 56,\n",
       " 'as': 57,\n",
       " '12': 58,\n",
       " 'il': 59,\n",
       " 'chris': 60,\n",
       " 'lee': 61,\n",
       " '02': 62,\n",
       " 'man': 63,\n",
       " 'life': 64,\n",
       " 'la': 65,\n",
       " '08': 66,\n",
       " 'spanish': 67,\n",
       " '06': 68,\n",
       " 'productions': 69,\n",
       " 'france': 70,\n",
       " 'william': 71,\n",
       " 'entertainment': 72,\n",
       " 'horror': 73,\n",
       " 'christopher': 74,\n",
       " 'jason': 75,\n",
       " 'thomas': 76,\n",
       " 'kevin': 77,\n",
       " '07': 78,\n",
       " 'bill': 79,\n",
       " 'canada': 80,\n",
       " 'germany': 81,\n",
       " 'daniel': 82,\n",
       " 'george': 83,\n",
       " 'jack': 84,\n",
       " '2006': 85,\n",
       " 'di': 86,\n",
       " 'mystery': 87,\n",
       " 'jr': 88,\n",
       " 'martin': 89,\n",
       " 'two': 90,\n",
       " 'him': 91,\n",
       " 'has': 92,\n",
       " 'are': 93,\n",
       " 'up': 94,\n",
       " 'jones': 95,\n",
       " 'joe': 96,\n",
       " 'stephen': 97,\n",
       " 'at': 98,\n",
       " 'but': 99,\n",
       " '2016': 100,\n",
       " '2003': 101,\n",
       " 'fantasy': 102,\n",
       " 'into': 103,\n",
       " 'de': 104,\n",
       " 'steve': 105,\n",
       " 'she': 106,\n",
       " '2011': 107,\n",
       " 'war': 108,\n",
       " 'tony': 109,\n",
       " '2008': 110,\n",
       " '2014': 111,\n",
       " 'brian': 112,\n",
       " 'story': 113,\n",
       " '2007': 114,\n",
       " 'will': 115,\n",
       " 'jennifer': 116,\n",
       " 'world': 117,\n",
       " '2013': 118,\n",
       " 'smith': 119,\n",
       " 'they': 120,\n",
       " 'charles': 121,\n",
       " 'e': 122,\n",
       " 'tim': 123,\n",
       " 'german': 124,\n",
       " 'american': 125,\n",
       " 'sam': 126,\n",
       " 'fox': 127,\n",
       " '2004': 128,\n",
       " 'one': 129,\n",
       " 'matthew': 130,\n",
       " 'ben': 131,\n",
       " 'biography': 132,\n",
       " '2012': 133,\n",
       " 'woman': 134,\n",
       " '2009': 135,\n",
       " 'animation': 136,\n",
       " '2017': 137,\n",
       " 'jean': 138,\n",
       " '2000': 139,\n",
       " 'anthony': 140,\n",
       " 'matt': 141,\n",
       " '2005': 142,\n",
       " 'film': 143,\n",
       " 'frank': 144,\n",
       " 'adam': 145,\n",
       " 'love': 146,\n",
       " 'bruce': 147,\n",
       " 'patrick': 148,\n",
       " 'out': 149,\n",
       " 'sci': 150,\n",
       " 'fi': 151,\n",
       " 'group': 152,\n",
       " 'danny': 153,\n",
       " '1999': 154,\n",
       " 'taylor': 155,\n",
       " '2010': 156,\n",
       " 'billy': 157,\n",
       " 'italian': 158,\n",
       " 'jim': 159,\n",
       " 'eric': 160,\n",
       " '2015': 161,\n",
       " 'nick': 162,\n",
       " 'bob': 163,\n",
       " '2002': 164,\n",
       " 'school': 165,\n",
       " 'miller': 166,\n",
       " 'sean': 167,\n",
       " 'home': 168,\n",
       " 'ryan': 169,\n",
       " 'must': 170,\n",
       " 'jonathan': 171,\n",
       " '2001': 172,\n",
       " 'it': 173,\n",
       " 'i': 174,\n",
       " 'allen': 175,\n",
       " 'williams': 176,\n",
       " 'be': 177,\n",
       " 'andrew': 178,\n",
       " 's': 179,\n",
       " 'find': 180,\n",
       " 'music': 181,\n",
       " 'friends': 182,\n",
       " 'alan': 183,\n",
       " 'd': 184,\n",
       " 'steven': 185,\n",
       " 'rob': 186,\n",
       " 'del': 187,\n",
       " 'jeff': 188,\n",
       " 'dan': 189,\n",
       " 'don': 190,\n",
       " 'wilson': 191,\n",
       " 'where': 192,\n",
       " '2': 193,\n",
       " 'howard': 194,\n",
       " 'century': 195,\n",
       " 'brown': 196,\n",
       " 'mike': 197,\n",
       " 'c': 198,\n",
       " 'davis': 199,\n",
       " 'mary': 200,\n",
       " 'high': 201,\n",
       " 'gary': 202,\n",
       " '1993': 203,\n",
       " 'christian': 204,\n",
       " 'josh': 205,\n",
       " 'jon': 206,\n",
       " 'joseph': 207,\n",
       " 'warner': 208,\n",
       " '1998': 209,\n",
       " 'finds': 210,\n",
       " 'about': 211,\n",
       " 'anderson': 212,\n",
       " 'elizabeth': 213,\n",
       " '2018': 214,\n",
       " 'jane': 215,\n",
       " 'anna': 216,\n",
       " 'jeremy': 217,\n",
       " 'kim': 218,\n",
       " 'them': 219,\n",
       " 'universal': 220,\n",
       " 'boy': 221,\n",
       " 'nicholas': 222,\n",
       " 'black': 223,\n",
       " 'alex': 224,\n",
       " 'l': 225,\n",
       " '18': 226,\n",
       " 'while': 227,\n",
       " 'ray': 228,\n",
       " 'old': 229,\n",
       " 'morgan': 230,\n",
       " 'history': 231,\n",
       " '30': 232,\n",
       " '24': 233,\n",
       " 'barry': 234,\n",
       " 'ron': 235,\n",
       " '13': 236,\n",
       " 'ed': 237,\n",
       " '16': 238,\n",
       " 'van': 239,\n",
       " 'amy': 240,\n",
       " 'moore': 241,\n",
       " '1996': 242,\n",
       " 'ian': 243,\n",
       " 'johnson': 244,\n",
       " 'day': 245,\n",
       " 'columbia': 246,\n",
       " '10000000': 247,\n",
       " 'dean': 248,\n",
       " 'jay': 249,\n",
       " '2019': 250,\n",
       " 'lewis': 251,\n",
       " '25': 252,\n",
       " 'paramount': 253,\n",
       " 'douglas': 254,\n",
       " 'ken': 255,\n",
       " 'kelly': 256,\n",
       " 'help': 257,\n",
       " 'three': 258,\n",
       " 'harris': 259,\n",
       " 'company': 260,\n",
       " 'le': 261,\n",
       " 'simon': 262,\n",
       " 'have': 263,\n",
       " 'anne': 264,\n",
       " '27': 265,\n",
       " '1995': 266,\n",
       " 'girl': 267,\n",
       " 'craig': 268,\n",
       " 'bros': 269,\n",
       " 'king': 270,\n",
       " 't': 271,\n",
       " '20': 272,\n",
       " 'r': 273,\n",
       " 'back': 274,\n",
       " 'city': 275,\n",
       " 'all': 276,\n",
       " '20000000': 277,\n",
       " 'green': 278,\n",
       " 'son': 279,\n",
       " 'russell': 280,\n",
       " 'roger': 281,\n",
       " 'becomes': 282,\n",
       " 'aaron': 283,\n",
       " 'eur': 284,\n",
       " 'm': 285,\n",
       " 'russian': 286,\n",
       " 'lives': 287,\n",
       " '28': 288,\n",
       " 'parker': 289,\n",
       " '14': 290,\n",
       " '1989': 291,\n",
       " 'down': 292,\n",
       " 'marc': 293,\n",
       " 'ii': 294,\n",
       " '19': 295,\n",
       " 'lawrence': 296,\n",
       " 'edward': 297,\n",
       " '15000000': 298,\n",
       " 'vincent': 299,\n",
       " 'during': 300,\n",
       " 'susan': 301,\n",
       " '22': 302,\n",
       " 'time': 303,\n",
       " 'justin': 304,\n",
       " 'jessica': 305,\n",
       " 'henry': 306,\n",
       " 'years': 307,\n",
       " 'jeffrey': 308,\n",
       " 'robin': 309,\n",
       " 'japanese': 310,\n",
       " 'small': 311,\n",
       " 'guy': 312,\n",
       " 'kate': 313,\n",
       " '23': 314,\n",
       " 'michelle': 315,\n",
       " '15': 316,\n",
       " 'against': 317,\n",
       " 'harry': 318,\n",
       " 'wife': 319,\n",
       " 'white': 320,\n",
       " '17': 321,\n",
       " 'mother': 322,\n",
       " '1991': 323,\n",
       " 'b': 324,\n",
       " '25000000': 325,\n",
       " 'which': 326,\n",
       " '21': 327,\n",
       " 'jordan': 328,\n",
       " 'best': 329,\n",
       " 'ann': 330,\n",
       " 'twentieth': 331,\n",
       " 'wright': 332,\n",
       " 'hall': 333,\n",
       " 'night': 334,\n",
       " 'lisa': 335,\n",
       " 'philip': 336,\n",
       " 'get': 337,\n",
       " 'un': 338,\n",
       " '1997': 339,\n",
       " 'todd': 340,\n",
       " 'dennis': 341,\n",
       " 'town': 342,\n",
       " 'italy': 343,\n",
       " 'take': 344,\n",
       " 'andy': 345,\n",
       " 'charlie': 346,\n",
       " 'death': 347,\n",
       " 'india': 348,\n",
       " 'line': 349,\n",
       " 'way': 350,\n",
       " 'year': 351,\n",
       " 'australia': 352,\n",
       " 'una': 353,\n",
       " '101': 354,\n",
       " 'sarah': 355,\n",
       " 'team': 356,\n",
       " 'greg': 357,\n",
       " 'over': 358,\n",
       " 'pat': 359,\n",
       " 'al': 360,\n",
       " '1983': 361,\n",
       " 'joel': 362,\n",
       " 'father': 363,\n",
       " 'york': 364,\n",
       " '1985': 365,\n",
       " 'wayne': 366,\n",
       " '30000000': 367,\n",
       " '110': 368,\n",
       " 'larry': 369,\n",
       " 'make': 370,\n",
       " 'emma': 371,\n",
       " 'alexander': 372,\n",
       " 'baker': 373,\n",
       " 'della': 374,\n",
       " 'tyler': 375,\n",
       " 'cooper': 376,\n",
       " 'stewart': 377,\n",
       " 'bell': 378,\n",
       " '1988': 379,\n",
       " '29': 380,\n",
       " '93': 381,\n",
       " 'roberts': 382,\n",
       " 'graham': 383,\n",
       " 'thompson': 384,\n",
       " 'jackson': 385,\n",
       " 'terry': 386,\n",
       " 'johnny': 387,\n",
       " 'rick': 388,\n",
       " 'max': 389,\n",
       " 'sport': 390,\n",
       " 'hill': 391,\n",
       " 'keith': 392,\n",
       " '100': 393,\n",
       " 'rachel': 394,\n",
       " '1987': 395,\n",
       " '5000000': 396,\n",
       " 'louis': 397,\n",
       " 'first': 398,\n",
       " '1994': 399,\n",
       " 'china': 400,\n",
       " 'gordon': 401,\n",
       " 'men': 402,\n",
       " 'college': 403,\n",
       " 'japan': 404,\n",
       " 'emily': 405,\n",
       " 'between': 406,\n",
       " 'barbara': 407,\n",
       " 'falls': 408,\n",
       " 'nancy': 409,\n",
       " '1992': 410,\n",
       " 'can': 411,\n",
       " 'spain': 412,\n",
       " 'julia': 413,\n",
       " 'murder': 414,\n",
       " '12000000': 415,\n",
       " 'own': 416,\n",
       " 'nicole': 417,\n",
       " '107': 418,\n",
       " 'little': 419,\n",
       " 'tommy': 420,\n",
       " 'g': 421,\n",
       " 'brad': 422,\n",
       " 'himself': 423,\n",
       " 'go': 424,\n",
       " 'diane': 425,\n",
       " 'become': 426,\n",
       " 'west': 427,\n",
       " 'jerry': 428,\n",
       " 'grant': 429,\n",
       " 'dave': 430,\n",
       " '90': 431,\n",
       " 'other': 432,\n",
       " 'cinema': 433,\n",
       " 'k': 434,\n",
       " 'nelson': 435,\n",
       " 'through': 436,\n",
       " 'marshall': 437,\n",
       " 'clark': 438,\n",
       " 'catherine': 439,\n",
       " 'kenneth': 440,\n",
       " 'save': 441,\n",
       " 'fred': 442,\n",
       " 'its': 443,\n",
       " 'p': 444,\n",
       " '97': 445,\n",
       " 'colin': 446,\n",
       " 'karen': 447,\n",
       " 'jamie': 448,\n",
       " 'friend': 449,\n",
       " '99': 450,\n",
       " '1990': 451,\n",
       " 'campbell': 452,\n",
       " 'order': 453,\n",
       " 'arabic': 454,\n",
       " '1986': 455,\n",
       " 'ted': 456,\n",
       " 'only': 457,\n",
       " '98': 458,\n",
       " 'benjamin': 459,\n",
       " '35000000': 460,\n",
       " 'collins': 461,\n",
       " 'eddie': 462,\n",
       " 'donald': 463,\n",
       " 'laura': 464,\n",
       " 'timothy': 465,\n",
       " 'disney': 466,\n",
       " 'maria': 467,\n",
       " 'movie': 468,\n",
       " 'brooks': 469,\n",
       " 'oliver': 470,\n",
       " 'brother': 471,\n",
       " 'four': 472,\n",
       " 'former': 473,\n",
       " 'patricia': 474,\n",
       " 'murphy': 475,\n",
       " 'rock': 476,\n",
       " '92': 477,\n",
       " '88': 478,\n",
       " 'carter': 479,\n",
       " 'julie': 480,\n",
       " 'f': 481,\n",
       " 'carl': 482,\n",
       " 'last': 483,\n",
       " '95': 484,\n",
       " '8000000': 485,\n",
       " '108': 486,\n",
       " 'what': 487,\n",
       " 'bobby': 488,\n",
       " 'before': 489,\n",
       " 'walter': 490,\n",
       " 'lauren': 491,\n",
       " 'bradley': 492,\n",
       " '1984': 493,\n",
       " 'mandarin': 494,\n",
       " 'gabriel': 495,\n",
       " 'per': 496,\n",
       " 'off': 497,\n",
       " '105': 498,\n",
       " 'jake': 499,\n",
       " 'blake': 500,\n",
       " 'mysterious': 501,\n",
       " 'von': 502,\n",
       " 'set': 503,\n",
       " '106': 504,\n",
       " '109': 505,\n",
       " 'fisher': 506,\n",
       " '91': 507,\n",
       " 'walt': 508,\n",
       " 'true': 509,\n",
       " 'gregory': 510,\n",
       " 'cameron': 511,\n",
       " '102': 512,\n",
       " 'house': 513,\n",
       " 'leslie': 514,\n",
       " 'international': 515,\n",
       " 'this': 516,\n",
       " 'ethan': 517,\n",
       " '94': 518,\n",
       " 'noah': 519,\n",
       " 'freeman': 520,\n",
       " '3000000': 521,\n",
       " 'warren': 522,\n",
       " 'pierre': 523,\n",
       " '96': 524,\n",
       " 'big': 525,\n",
       " 'rose': 526,\n",
       " 'people': 527,\n",
       " 'carlos': 528,\n",
       " 'albert': 529,\n",
       " 'gets': 530,\n",
       " 'agent': 531,\n",
       " 'grace': 532,\n",
       " '3': 533,\n",
       " 'khan': 534,\n",
       " 'edwards': 535,\n",
       " 'glenn': 536,\n",
       " 'come': 537,\n",
       " 'ross': 538,\n",
       " '6000000': 539,\n",
       " 'mexico': 540,\n",
       " '1981': 541,\n",
       " 'jesse': 542,\n",
       " 'star': 543,\n",
       " 'together': 544,\n",
       " 'you': 545,\n",
       " 'daughter': 546,\n",
       " '120': 547,\n",
       " 'park': 548,\n",
       " 'being': 549,\n",
       " 'begins': 550,\n",
       " 'amanda': 551,\n",
       " 'kyle': 552,\n",
       " 'hindi': 553,\n",
       " 'ward': 554,\n",
       " '2000000': 555,\n",
       " 'luke': 556,\n",
       " 'jan': 557,\n",
       " 'hong': 558,\n",
       " 'owen': 559,\n",
       " '40000000': 560,\n",
       " 'alice': 561,\n",
       " 'helen': 562,\n",
       " 'not': 563,\n",
       " 'past': 564,\n",
       " 'austin': 565,\n",
       " '117': 566,\n",
       " 'killer': 567,\n",
       " 'south': 568,\n",
       " 'linda': 569,\n",
       " 'ashley': 570,\n",
       " 'away': 571,\n",
       " 'dead': 572,\n",
       " 'vanessa': 573,\n",
       " 'rich': 574,\n",
       " 'jimmy': 575,\n",
       " '112': 576,\n",
       " 'harvey': 577,\n",
       " 'adams': 578,\n",
       " 'turn': 579,\n",
       " 'discovers': 580,\n",
       " 'cox': 581,\n",
       " 'earth': 582,\n",
       " 'walker': 583,\n",
       " 'british': 584,\n",
       " 'victor': 585,\n",
       " 'reynolds': 586,\n",
       " 'cross': 587,\n",
       " 'doug': 588,\n",
       " 'mitchell': 589,\n",
       " 'cook': 590,\n",
       " 'relationship': 591,\n",
       " 'more': 592,\n",
       " 'art': 593,\n",
       " 'evans': 594,\n",
       " 'murray': 595,\n",
       " '13000000': 596,\n",
       " 'studios': 597,\n",
       " 'rodriguez': 598,\n",
       " 'returns': 599,\n",
       " 'living': 600,\n",
       " 'children': 601,\n",
       " '4000000': 602,\n",
       " 'brothers': 603,\n",
       " 'frances': 604,\n",
       " 'lucas': 605,\n",
       " '116': 606,\n",
       " 'marie': 607,\n",
       " 'goes': 608,\n",
       " 'walsh': 609,\n",
       " 'kristen': 610,\n",
       " 'dana': 611,\n",
       " 'most': 612,\n",
       " 'was': 613,\n",
       " 'francis': 614,\n",
       " 'richardson': 615,\n",
       " 'evil': 616,\n",
       " '26': 617,\n",
       " 'each': 618,\n",
       " 'musical': 619,\n",
       " 'rebecca': 620,\n",
       " '50000000': 621,\n",
       " 'teenage': 622,\n",
       " 'damon': 623,\n",
       " 'nathan': 624,\n",
       " 'based': 625,\n",
       " 'takes': 626,\n",
       " 'seth': 627,\n",
       " 'cohen': 628,\n",
       " 'knight': 629,\n",
       " 'live': 630,\n",
       " '1000000': 631,\n",
       " 'police': 632,\n",
       " 'washington': 633,\n",
       " 'foster': 634,\n",
       " 'stuart': 635,\n",
       " 'comes': 636,\n",
       " 'been': 637,\n",
       " 'deborah': 638,\n",
       " 'husband': 639,\n",
       " 'clarke': 640,\n",
       " 'phil': 641,\n",
       " 'singer': 642,\n",
       " 'leonard': 643,\n",
       " 'joan': 644,\n",
       " 'jackie': 645,\n",
       " 'couple': 646,\n",
       " 'morris': 647,\n",
       " 'hunter': 648,\n",
       " 'hart': 649,\n",
       " 'goldwyn': 650,\n",
       " 'journey': 651,\n",
       " '104': 652,\n",
       " 'jacob': 653,\n",
       " 'or': 654,\n",
       " 'claudia': 655,\n",
       " 'latin': 656,\n",
       " 'norman': 657,\n",
       " '1982': 658,\n",
       " 'maggie': 659,\n",
       " 'secret': 660,\n",
       " 'h': 661,\n",
       " 'ralph': 662,\n",
       " '18000000': 663,\n",
       " 'game': 664,\n",
       " 'bernard': 665,\n",
       " 'wes': 666,\n",
       " 'run': 667,\n",
       " 'fight': 668,\n",
       " 'woods': 669,\n",
       " 'left': 670,\n",
       " 'child': 671,\n",
       " 'phillips': 672,\n",
       " 'wong': 673,\n",
       " 'wood': 674,\n",
       " 'joshua': 675,\n",
       " 'work': 676,\n",
       " 'leo': 677,\n",
       " 'student': 678,\n",
       " 'named': 679,\n",
       " 'mayer': 680,\n",
       " 'perry': 681,\n",
       " 'end': 682,\n",
       " 'good': 683,\n",
       " 'married': 684,\n",
       " 'detective': 685,\n",
       " 'spencer': 686,\n",
       " 'geoffrey': 687,\n",
       " 'street': 688,\n",
       " 'hugh': 689,\n",
       " 'bennett': 690,\n",
       " 'drew': 691,\n",
       " 'angela': 692,\n",
       " 'christina': 693,\n",
       " '85': 694,\n",
       " 'kurt': 695,\n",
       " 'local': 696,\n",
       " 'miguel': 697,\n",
       " 'bryan': 698,\n",
       " 'los': 699,\n",
       " '89': 700,\n",
       " 'brandon': 701,\n",
       " 'evan': 702,\n",
       " '113': 703,\n",
       " 'lloyd': 704,\n",
       " 'gene': 705,\n",
       " 'liam': 706,\n",
       " 'banks': 707,\n",
       " 'marriage': 708,\n",
       " 'camp': 709,\n",
       " 'u': 710,\n",
       " 'money': 711,\n",
       " 'turns': 712,\n",
       " 'no': 713,\n",
       " 'tries': 714,\n",
       " 'toby': 715,\n",
       " 'lost': 716,\n",
       " 'michel': 717,\n",
       " 'arthur': 718,\n",
       " 'land': 719,\n",
       " 'meets': 720,\n",
       " 'me': 721,\n",
       " '103': 722,\n",
       " 'trying': 723,\n",
       " 'christine': 724,\n",
       " 'battle': 725,\n",
       " '87': 726,\n",
       " 'shane': 727,\n",
       " 'kong': 728,\n",
       " 'ex': 729,\n",
       " 'shawn': 730,\n",
       " 'drug': 731,\n",
       " 'gray': 732,\n",
       " 'lucy': 733,\n",
       " 'ford': 734,\n",
       " 'ali': 735,\n",
       " 'nicolas': 736,\n",
       " 'hoffman': 737,\n",
       " 'jenkins': 738,\n",
       " 'long': 739,\n",
       " 'seymour': 740,\n",
       " '115': 741,\n",
       " 'forced': 742,\n",
       " 'media': 743,\n",
       " 'lynn': 744,\n",
       " '118': 745,\n",
       " 'officer': 746,\n",
       " 'just': 747,\n",
       " '7000000': 748,\n",
       " '14000000': 749,\n",
       " 'wants': 750,\n",
       " 'business': 751,\n",
       " 'career': 752,\n",
       " 'power': 753,\n",
       " 'penn': 754,\n",
       " 'griffin': 755,\n",
       " 'carmen': 756,\n",
       " 'garcia': 757,\n",
       " 'leon': 758,\n",
       " 'chinese': 759,\n",
       " 'angeles': 760,\n",
       " 'iii': 761,\n",
       " 'robinson': 762,\n",
       " 'hunt': 763,\n",
       " 'henderson': 764,\n",
       " 'gibson': 765,\n",
       " 'annie': 766,\n",
       " 'con': 767,\n",
       " 'julian': 768,\n",
       " 'now': 769,\n",
       " 'struggling': 770,\n",
       " 'hes': 771,\n",
       " 'human': 772,\n",
       " 'country': 773,\n",
       " 'woody': 774,\n",
       " 'burt': 775,\n",
       " 'job': 776,\n",
       " 'themselves': 777,\n",
       " 'jos√©': 778,\n",
       " 'dog': 779,\n",
       " 'women': 780,\n",
       " 'elliott': 781,\n",
       " 'london': 782,\n",
       " 'days': 783,\n",
       " 'claude': 784,\n",
       " 'united': 785,\n",
       " 'red': 786,\n",
       " 'childhood': 787,\n",
       " 'neil': 788,\n",
       " 'strong': 789,\n",
       " 'discover': 790,\n",
       " 'wallace': 791,\n",
       " 'parents': 792,\n",
       " 'try': 793,\n",
       " 'touchstone': 794,\n",
       " '60000000': 795,\n",
       " '114': 796,\n",
       " 'louise': 797,\n",
       " 'screen': 798,\n",
       " 'decides': 799,\n",
       " 'casey': 800,\n",
       " 'gay': 801,\n",
       " 'future': 802,\n",
       " 'brent': 803,\n",
       " 'once': 804,\n",
       " 'like': 805,\n",
       " 'carroll': 806,\n",
       " '86': 807,\n",
       " 'mel': 808,\n",
       " 'chuck': 809,\n",
       " 'da': 810,\n",
       " 'w': 811,\n",
       " 'charlotte': 812,\n",
       " 'lily': 813,\n",
       " 'metro': 814,\n",
       " 'mgm': 815,\n",
       " 'kathy': 816,\n",
       " 'bridges': 817,\n",
       " 'baldwin': 818,\n",
       " 'dick': 819,\n",
       " 'face': 820,\n",
       " 'called': 821,\n",
       " 'mission': 822,\n",
       " 'road': 823,\n",
       " 'les': 824,\n",
       " 'mr': 825,\n",
       " 'leigh': 826,\n",
       " '111': 827,\n",
       " 'philippe': 828,\n",
       " 'stop': 829,\n",
       " 'lindsay': 830,\n",
       " 'burton': 831,\n",
       " 'quinn': 832,\n",
       " 'burns': 833,\n",
       " 'stanley': 834,\n",
       " 'race': 835,\n",
       " 'bond': 836,\n",
       " 'lou': 837,\n",
       " 'curtis': 838,\n",
       " 'eva': 839,\n",
       " 'car': 840,\n",
       " 'tristar': 841,\n",
       " '9000000': 842,\n",
       " 'across': 843,\n",
       " 'another': 844,\n",
       " 'cantonese': 845,\n",
       " 'lopez': 846,\n",
       " 'kristin': 847,\n",
       " 'soon': 848,\n",
       " 'simmons': 849,\n",
       " 'joey': 850,\n",
       " '1979': 851,\n",
       " 'under': 852,\n",
       " 'summer': 853,\n",
       " 'how': 854,\n",
       " 'around': 855,\n",
       " 'willis': 856,\n",
       " 'sullivan': 857,\n",
       " 'law': 858,\n",
       " 'herself': 859,\n",
       " 'return': 860,\n",
       " 'cop': 861,\n",
       " 'brett': 862,\n",
       " 'then': 863,\n",
       " 'party': 864,\n",
       " 'jill': 865,\n",
       " 'mccarthy': 866,\n",
       " 'jo': 867,\n",
       " 'dylan': 868,\n",
       " 'clint': 869,\n",
       " 'dark': 870,\n",
       " 'gbp': 871,\n",
       " 'soldier': 872,\n",
       " 'o': 873,\n",
       " 'boyd': 874,\n",
       " '119': 875,\n",
       " 'america': 876,\n",
       " 'girls': 877,\n",
       " 'series': 878,\n",
       " 'lo': 879,\n",
       " 'melissa': 880,\n",
       " 'sister': 881,\n",
       " '22000000': 882,\n",
       " 'erin': 883,\n",
       " 'mann': 884,\n",
       " 'personal': 885,\n",
       " 'raymond': 886,\n",
       " 'boss': 887,\n",
       " 'roy': 888,\n",
       " 'el': 889,\n",
       " 'samuel': 890,\n",
       " 'put': 891,\n",
       " 'boys': 892,\n",
       " 'katherine': 893,\n",
       " 'madison': 894,\n",
       " 'cusack': 895,\n",
       " 'marcus': 896,\n",
       " '1980': 897,\n",
       " 'harold': 898,\n",
       " 'carol': 899,\n",
       " 'brendan': 900,\n",
       " 'czech': 901,\n",
       " 'hope': 902,\n",
       " 'middle': 903,\n",
       " 'dillon': 904,\n",
       " 'real': 905,\n",
       " 'coen': 906,\n",
       " 'band': 907,\n",
       " 'kennedy': 908,\n",
       " 'diana': 909,\n",
       " '122': 910,\n",
       " 'hamilton': 911,\n",
       " 'malcolm': 912,\n",
       " 'dreamworks': 913,\n",
       " 'rescue': 914,\n",
       " 'criminal': 915,\n",
       " 'natalie': 916,\n",
       " 'revenge': 917,\n",
       " 'chan': 918,\n",
       " 'five': 919,\n",
       " 'dreams': 920,\n",
       " 'stone': 921,\n",
       " 'tara': 922,\n",
       " 'trip': 923,\n",
       " '2500000': 924,\n",
       " 'kane': 925,\n",
       " 'denmark': 926,\n",
       " 'sandler': 927,\n",
       " 'craven': 928,\n",
       " 'alison': 929,\n",
       " 'caroline': 930,\n",
       " 'due': 931,\n",
       " 'wendy': 932,\n",
       " 'katie': 933,\n",
       " 'claire': 934,\n",
       " 'protect': 935,\n",
       " 'andrea': 936,\n",
       " 'vita': 937,\n",
       " 'inr': 938,\n",
       " 'control': 939,\n",
       " 'kirk': 940,\n",
       " 'davies': 941,\n",
       " 'hollywood': 942,\n",
       " 'production': 943,\n",
       " 'ivan': 944,\n",
       " 'goodman': 945,\n",
       " 'princess': 946,\n",
       " 'sylvester': 947,\n",
       " 'chen': 948,\n",
       " 'li': 949,\n",
       " 'there': 950,\n",
       " 'luis': 951,\n",
       " 'kathryn': 952,\n",
       " 'may': 953,\n",
       " 'rhys': 954,\n",
       " 'beth': 955,\n",
       " 'donna': 956,\n",
       " 'reed': 957,\n",
       " 'shannon': 958,\n",
       " 'toni': 959,\n",
       " 'hopkins': 960,\n",
       " 'ana': 961,\n",
       " 'baron': 962,\n",
       " 'brooke': 963,\n",
       " 'however': 964,\n",
       " 'thornton': 965,\n",
       " 'hebrew': 966,\n",
       " 'belgium': 967,\n",
       " 'follows': 968,\n",
       " '121': 969,\n",
       " 'bailey': 970,\n",
       " 'wild': 971,\n",
       " 'korean': 972,\n",
       " 'plans': 973,\n",
       " 'adrian': 974,\n",
       " 'sharon': 975,\n",
       " 'shirley': 976,\n",
       " 'killed': 977,\n",
       " 'garrett': 978,\n",
       " 'meet': 979,\n",
       " 'beautiful': 980,\n",
       " 'lynch': 981,\n",
       " 'sandra': 982,\n",
       " 'keaton': 983,\n",
       " 'allison': 984,\n",
       " 'zoe': 985,\n",
       " 'paula': 986,\n",
       " 'logan': 987,\n",
       " 'cruz': 988,\n",
       " 'place': 989,\n",
       " 'hal': 990,\n",
       " 'struggles': 991,\n",
       " 'stephanie': 992,\n",
       " 'book': 993,\n",
       " 'dei': 994,\n",
       " 'gang': 995,\n",
       " 'derek': 996,\n",
       " 'allan': 997,\n",
       " 'non': 998,\n",
       " 'wang': 999,\n",
       " 'events': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(lower_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[10956 hot fuzz hot fuzz 2007 2007-08-24 action, comedy, mystery\\n 121 uk, france english edgar wright edgar wright, simon pegg\\n studiocanal\\n simon pegg, martin freeman, bill nighy, robert popper, joe cornish, chris waitt, eric mason, billie whitelaw, nick frost, peter wight, julia deakin, tom strode walton, troy woollan, rory lowings, bill bailey\\n a skilled london police officer is transferred to a small town with a dark secret.\\n gbp 8000000]'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1150, 7099, 1150, 7099,  114,  114,   66,  233,   21,   11,   87,\n",
       "        969,   31,   70,    3, 2085,  332, 2085,  332,  262, 2771, 4020,\n",
       "        262, 2771,   89,  520,   79, 2772,   23,   96, 2773,   60,  160,\n",
       "       1151, 4021, 7100,  162, 1542,   34, 5127,  413, 7101,   39, 1543,\n",
       "       1690, 2387,   79,  970,    1, 3306,  782,  632,  746,   15,    4,\n",
       "          1,  311,  342,   16,    1,  870,  660,  871,  485])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences([str(item).lower() for item in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad and truncate sequences\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.10994764397905"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722513089005236"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1528, 93)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1150, 7099, 1150, 7099,  114,  114,   66,  233,   21,   11,   87,\n",
       "        969,   31,   70,    3, 2085,  332, 2085,  332,  262, 2771, 4020,\n",
       "        262, 2771,   89,  520,   79, 2772,   23,   96, 2773,   60,  160,\n",
       "       1151, 4021, 7100,  162, 1542,   34, 5127,  413, 7101,   39, 1543,\n",
       "       1690, 2387,   79,  970,    1, 3306,  782,  632,  746,   15,    4,\n",
       "          1,  311,  342,   16,    1,  870,  660,  871,  485])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0, 1150, 7099, 1150, 7099,\n",
       "        114,  114,   66,  233,   21,   11,   87,  969,   31,   70,    3,\n",
       "       2085,  332, 2085,  332,  262, 2771, 4020,  262, 2771,   89,  520,\n",
       "         79, 2772,   23,   96, 2773,   60,  160, 1151, 4021, 7100,  162,\n",
       "       1542,   34, 5127,  413, 7101,   39, 1543, 1690, 2387,   79,  970,\n",
       "          1, 3306,  782,  632,  746,   15,    4,    1,  311,  342,   16,\n",
       "          1,  870,  660,  871,  485])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[10956 Hot Fuzz Hot Fuzz 2007 2007-08-24 Action, Comedy, Mystery\\n 121 UK, France English Edgar Wright Edgar Wright, Simon Pegg\\n StudioCanal\\n Simon Pegg, Martin Freeman, Bill Nighy, Robert Popper, Joe Cornish, Chris Waitt, Eric Mason, Billie Whitelaw, Nick Frost, Peter Wight, Julia Deakin, Tom Strode Walton, Troy Woollan, Rory Lowings, Bill Bailey\\n A skilled London police officer is transferred to a small town with a dark secret.\\n GBP 8000000]'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot fuzz hot fuzz 2007 2007 08 24 action comedy mystery 121 uk france english edgar wright edgar wright simon pegg studiocanal simon pegg martin freeman bill nighy robert joe cornish chris eric mason billie whitelaw nick frost peter wight julia deakin tom walton troy rory bill bailey a skilled london police officer is to a small town with a dark secret gbp 8000000'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_size = 8\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(GRU(units=32, return_sequences=True))\n",
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_embedding (Embedding)  (None, 93, 8)            80000     \n",
      "                                                                 \n",
      " gru_93 (GRU)                (None, 93, 64)            14208     \n",
      "                                                                 \n",
      " gru_94 (GRU)                (None, 93, 64)            24960     \n",
      "                                                                 \n",
      " gru_95 (GRU)                (None, 93, 32)            9408      \n",
      "                                                                 \n",
      " gru_96 (GRU)                (None, 93, 16)            2400      \n",
      "                                                                 \n",
      " gru_97 (GRU)                (None, 93, 8)             624       \n",
      "                                                                 \n",
      " gru_98 (GRU)                (None, 4)                 168       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,778\n",
      "Trainable params: 131,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   205569,    205569],\n",
       "       [ 23637265,  80743363],\n",
       "       [113804681, 222104681],\n",
       "       ...,\n",
       "       [ 36144000,  36179290],\n",
       "       [ 19889299,  19889299],\n",
       "       [ 11901145,  18096691]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 8s 68ms/step - loss: -4594411.0000 - accuracy: 0.6355\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -24842704.0000 - accuracy: 0.6656\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -47424076.0000 - accuracy: 0.6656\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -58036560.0000 - accuracy: 0.6656\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -64723416.0000 - accuracy: 0.6656\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -68454512.0000 - accuracy: 0.6656\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -72570072.0000 - accuracy: 0.6656\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -76373488.0000 - accuracy: 0.6656\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -79934344.0000 - accuracy: 0.6656\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -83260992.0000 - accuracy: 0.6656\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -86562680.0000 - accuracy: 0.6656\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -89595016.0000 - accuracy: 0.6656\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -92603416.0000 - accuracy: 0.6656\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -95386336.0000 - accuracy: 0.6656\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -98198880.0000 - accuracy: 0.6656\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -100786752.0000 - accuracy: 0.6656\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -103304040.0000 - accuracy: 0.6656\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -105864592.0000 - accuracy: 0.6656\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -108198496.0000 - accuracy: 0.6656\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -110559808.0000 - accuracy: 0.6656\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -112812160.0000 - accuracy: 0.6656\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -115085312.0000 - accuracy: 0.6656\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -117269328.0000 - accuracy: 0.6656\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -119436016.0000 - accuracy: 0.6656\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -121552528.0000 - accuracy: 0.6656\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -123586464.0000 - accuracy: 0.6656\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -125695280.0000 - accuracy: 0.6656\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -127690744.0000 - accuracy: 0.6656\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -129742376.0000 - accuracy: 0.6656\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -131735104.0000 - accuracy: 0.6656\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -133739440.0000 - accuracy: 0.6656\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -135675392.0000 - accuracy: 0.6656\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -137605936.0000 - accuracy: 0.6656\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -139514256.0000 - accuracy: 0.6656\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -141453824.0000 - accuracy: 0.6656\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -143322320.0000 - accuracy: 0.6656\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -145308416.0000 - accuracy: 0.6656\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -147158992.0000 - accuracy: 0.6656\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -149023840.0000 - accuracy: 0.6656\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -150916128.0000 - accuracy: 0.6656\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -152742496.0000 - accuracy: 0.6656\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -154621984.0000 - accuracy: 0.6656\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -156480992.0000 - accuracy: 0.6656\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 61ms/step - loss: -158348816.0000 - accuracy: 0.6656\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -160104592.0000 - accuracy: 0.6656\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -161965712.0000 - accuracy: 0.6656\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 72ms/step - loss: -163827248.0000 - accuracy: 0.6656\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -165622256.0000 - accuracy: 0.6656\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -167464544.0000 - accuracy: 0.6656\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -169243280.0000 - accuracy: 0.6656\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -171079520.0000 - accuracy: 0.6656\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -172884576.0000 - accuracy: 0.6656\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -174690560.0000 - accuracy: 0.6656\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -176465712.0000 - accuracy: 0.6656\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -178227456.0000 - accuracy: 0.6656\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -180043136.0000 - accuracy: 0.6656\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -181835488.0000 - accuracy: 0.6656\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -183626208.0000 - accuracy: 0.6656\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -185370704.0000 - accuracy: 0.6656\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -187174336.0000 - accuracy: 0.6656\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -188942048.0000 - accuracy: 0.6656\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -190707568.0000 - accuracy: 0.6656\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -192513504.0000 - accuracy: 0.6656\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -194257408.0000 - accuracy: 0.6656\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -196051088.0000 - accuracy: 0.6656\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 73ms/step - loss: -197778944.0000 - accuracy: 0.6656\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -199572832.0000 - accuracy: 0.6656\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -201305488.0000 - accuracy: 0.6656\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -203027328.0000 - accuracy: 0.6656\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -204843968.0000 - accuracy: 0.6656\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -206578560.0000 - accuracy: 0.6656\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -208349600.0000 - accuracy: 0.6656\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -210101872.0000 - accuracy: 0.6656\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -211833728.0000 - accuracy: 0.6656\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -213572048.0000 - accuracy: 0.6656\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -215349280.0000 - accuracy: 0.6656\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -217133184.0000 - accuracy: 0.6656\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -218794272.0000 - accuracy: 0.6656\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -220527648.0000 - accuracy: 0.6656\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 52ms/step - loss: -222333888.0000 - accuracy: 0.6656\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 66ms/step - loss: -224020016.0000 - accuracy: 0.6656\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -225808080.0000 - accuracy: 0.6656\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -227546640.0000 - accuracy: 0.6656\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -229245872.0000 - accuracy: 0.6656\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -230957424.0000 - accuracy: 0.6656\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -232762080.0000 - accuracy: 0.6656\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -234467632.0000 - accuracy: 0.6656\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -236208208.0000 - accuracy: 0.6656\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -237911856.0000 - accuracy: 0.6656\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -239672880.0000 - accuracy: 0.6656\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -241380288.0000 - accuracy: 0.6656\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -243092048.0000 - accuracy: 0.6656\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -244839664.0000 - accuracy: 0.6656\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -246562144.0000 - accuracy: 0.6656\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -248313904.0000 - accuracy: 0.6656\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -250030752.0000 - accuracy: 0.6656\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -251747664.0000 - accuracy: 0.6656\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -253433760.0000 - accuracy: 0.6656\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -255195504.0000 - accuracy: 0.6656\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -256894672.0000 - accuracy: 0.6656\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -258609008.0000 - accuracy: 0.6656\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -260342592.0000 - accuracy: 0.6656\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -262061744.0000 - accuracy: 0.6656\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -263770000.0000 - accuracy: 0.6656\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -265528304.0000 - accuracy: 0.6656\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -267208400.0000 - accuracy: 0.6656\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -268945280.0000 - accuracy: 0.6656\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -270630880.0000 - accuracy: 0.6656\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -272341344.0000 - accuracy: 0.6656\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -274030240.0000 - accuracy: 0.6656\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -275742784.0000 - accuracy: 0.6656\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -277471616.0000 - accuracy: 0.6656\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -279184832.0000 - accuracy: 0.6656\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -280936864.0000 - accuracy: 0.6656\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -282627360.0000 - accuracy: 0.6656\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -284340128.0000 - accuracy: 0.6656\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -286060544.0000 - accuracy: 0.6656\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -287743360.0000 - accuracy: 0.6656\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -289458304.0000 - accuracy: 0.6656\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -291192032.0000 - accuracy: 0.6656\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -292872096.0000 - accuracy: 0.6656\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -294609408.0000 - accuracy: 0.6656\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -296320448.0000 - accuracy: 0.6656\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -298003936.0000 - accuracy: 0.6656\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -299712288.0000 - accuracy: 0.6656\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -301419488.0000 - accuracy: 0.6656\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -303137120.0000 - accuracy: 0.6656\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -304828832.0000 - accuracy: 0.6656\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -306585056.0000 - accuracy: 0.6656\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -308225248.0000 - accuracy: 0.6656\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -309919264.0000 - accuracy: 0.6656\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -311653472.0000 - accuracy: 0.6656\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -313351136.0000 - accuracy: 0.6656\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -315057152.0000 - accuracy: 0.6656\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -316777216.0000 - accuracy: 0.6656\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -318384736.0000 - accuracy: 0.6656\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 64ms/step - loss: -320069856.0000 - accuracy: 0.6656\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -321784992.0000 - accuracy: 0.6656\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -323566752.0000 - accuracy: 0.6656\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -325223776.0000 - accuracy: 0.6656\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -326949696.0000 - accuracy: 0.6656\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 58ms/step - loss: -328639008.0000 - accuracy: 0.6656\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 61ms/step - loss: -330343264.0000 - accuracy: 0.6656\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -332085952.0000 - accuracy: 0.6656\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -333724768.0000 - accuracy: 0.6656\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -335440704.0000 - accuracy: 0.6656\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -337166880.0000 - accuracy: 0.6656\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -338859776.0000 - accuracy: 0.6656\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -340539648.0000 - accuracy: 0.6656\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -342238272.0000 - accuracy: 0.6656\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -343914048.0000 - accuracy: 0.6656\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -345610016.0000 - accuracy: 0.6656\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -347342080.0000 - accuracy: 0.6656\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -349036416.0000 - accuracy: 0.6656\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -350700448.0000 - accuracy: 0.6656\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -352381632.0000 - accuracy: 0.6656\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -354115232.0000 - accuracy: 0.6656\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -355799648.0000 - accuracy: 0.6656\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -357494592.0000 - accuracy: 0.6656\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -359142912.0000 - accuracy: 0.6656\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -360899456.0000 - accuracy: 0.6656\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 29ms/step - loss: -362566976.0000 - accuracy: 0.6656\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -364270912.0000 - accuracy: 0.6656\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 77ms/step - loss: -365935392.0000 - accuracy: 0.6656\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -367628256.0000 - accuracy: 0.6656\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: -369331232.0000 - accuracy: 0.6656\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -370998912.0000 - accuracy: 0.6656\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -372711456.0000 - accuracy: 0.6656\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -374414848.0000 - accuracy: 0.6656\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 78ms/step - loss: -376059712.0000 - accuracy: 0.6656\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -377822688.0000 - accuracy: 0.6656\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -379455360.0000 - accuracy: 0.6656\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -381150816.0000 - accuracy: 0.6656\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -382848320.0000 - accuracy: 0.6656\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -384537632.0000 - accuracy: 0.6656\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -386197600.0000 - accuracy: 0.6656\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 52ms/step - loss: -387907488.0000 - accuracy: 0.6656\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 58ms/step - loss: -389602112.0000 - accuracy: 0.6656\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 59ms/step - loss: -391340128.0000 - accuracy: 0.6656\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 56ms/step - loss: -392999616.0000 - accuracy: 0.6656\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -394656064.0000 - accuracy: 0.6656\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -396369440.0000 - accuracy: 0.6656\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -397968512.0000 - accuracy: 0.6656\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -399735680.0000 - accuracy: 0.6656\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -401381152.0000 - accuracy: 0.6656\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -403111808.0000 - accuracy: 0.6656\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -404765088.0000 - accuracy: 0.6656\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -406509376.0000 - accuracy: 0.6656\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 58ms/step - loss: -408198432.0000 - accuracy: 0.6656\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 52ms/step - loss: -409863360.0000 - accuracy: 0.6656\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -411532224.0000 - accuracy: 0.6656\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -413159968.0000 - accuracy: 0.6656\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -414882944.0000 - accuracy: 0.6656\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -416579072.0000 - accuracy: 0.6656\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 58ms/step - loss: -418254400.0000 - accuracy: 0.6656\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -419953056.0000 - accuracy: 0.6656\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -421636992.0000 - accuracy: 0.6656\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -423352864.0000 - accuracy: 0.6656\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -424999552.0000 - accuracy: 0.6656\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -426688128.0000 - accuracy: 0.6656\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -428378336.0000 - accuracy: 0.6656\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -430081888.0000 - accuracy: 0.6656\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 59ms/step - loss: -431729824.0000 - accuracy: 0.6656\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -433449472.0000 - accuracy: 0.6656\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -435085536.0000 - accuracy: 0.6656\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -436771360.0000 - accuracy: 0.6656\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -438506336.0000 - accuracy: 0.6656\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -440174816.0000 - accuracy: 0.6656\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -441760000.0000 - accuracy: 0.6656\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -443441792.0000 - accuracy: 0.6656\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -445096160.0000 - accuracy: 0.6656\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 65ms/step - loss: -446654816.0000 - accuracy: 0.6656\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -448378944.0000 - accuracy: 0.6656\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -450089120.0000 - accuracy: 0.6656\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -451811264.0000 - accuracy: 0.6656\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -453496384.0000 - accuracy: 0.6656\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -455246112.0000 - accuracy: 0.6656\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -456928928.0000 - accuracy: 0.6656\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -458620928.0000 - accuracy: 0.6656\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -460329536.0000 - accuracy: 0.6656\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -462029216.0000 - accuracy: 0.6656\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -463661664.0000 - accuracy: 0.6656\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -465397728.0000 - accuracy: 0.6656\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -466979520.0000 - accuracy: 0.6656\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -468737504.0000 - accuracy: 0.6656\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -470417824.0000 - accuracy: 0.6656\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -472071680.0000 - accuracy: 0.6656\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -473790336.0000 - accuracy: 0.6656\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -475458528.0000 - accuracy: 0.6656\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -477121888.0000 - accuracy: 0.6656\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -478818528.0000 - accuracy: 0.6656\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -480519360.0000 - accuracy: 0.6656\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 58ms/step - loss: -482209312.0000 - accuracy: 0.6656\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -483893856.0000 - accuracy: 0.6656\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -485557952.0000 - accuracy: 0.6656\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -487196768.0000 - accuracy: 0.6656\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -488900736.0000 - accuracy: 0.6656\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 34ms/step - loss: -490591744.0000 - accuracy: 0.6656\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -492202944.0000 - accuracy: 0.6656\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -493982304.0000 - accuracy: 0.6656\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -495614656.0000 - accuracy: 0.6656\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -497291584.0000 - accuracy: 0.6656\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -498963648.0000 - accuracy: 0.6656\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -500646176.0000 - accuracy: 0.6656\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -502324256.0000 - accuracy: 0.6656\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -504014784.0000 - accuracy: 0.6656\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -505708416.0000 - accuracy: 0.6656\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -507358752.0000 - accuracy: 0.6656\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -509032992.0000 - accuracy: 0.6656\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -510693536.0000 - accuracy: 0.6656\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -512404640.0000 - accuracy: 0.6656\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 33ms/step - loss: -514060576.0000 - accuracy: 0.6656\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -515763264.0000 - accuracy: 0.6656\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -517442720.0000 - accuracy: 0.6656\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -519061120.0000 - accuracy: 0.6656\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -520735968.0000 - accuracy: 0.6656\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -522467584.0000 - accuracy: 0.6656\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -524168480.0000 - accuracy: 0.6656\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -525802400.0000 - accuracy: 0.6656\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -527476448.0000 - accuracy: 0.6656\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: -529161952.0000 - accuracy: 0.6656\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -530824960.0000 - accuracy: 0.6656\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -532501888.0000 - accuracy: 0.6656\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 52ms/step - loss: -534196448.0000 - accuracy: 0.6656\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -535874272.0000 - accuracy: 0.6656\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -537512384.0000 - accuracy: 0.6656\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -539198464.0000 - accuracy: 0.6656\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -540928768.0000 - accuracy: 0.6656\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -542555904.0000 - accuracy: 0.6656\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 56ms/step - loss: -544236416.0000 - accuracy: 0.6656\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -545888896.0000 - accuracy: 0.6656\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -547639936.0000 - accuracy: 0.6656\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 62ms/step - loss: -549236928.0000 - accuracy: 0.6656\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -550940544.0000 - accuracy: 0.6656\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -552628608.0000 - accuracy: 0.6656\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -554264512.0000 - accuracy: 0.6656\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 52ms/step - loss: -555977408.0000 - accuracy: 0.6656\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -557646784.0000 - accuracy: 0.6656\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 57ms/step - loss: -559279360.0000 - accuracy: 0.6656\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -561028160.0000 - accuracy: 0.6656\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -562657728.0000 - accuracy: 0.6656\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -564367360.0000 - accuracy: 0.6656\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -566013952.0000 - accuracy: 0.6656\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -567669120.0000 - accuracy: 0.6656\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 56ms/step - loss: -569337280.0000 - accuracy: 0.6656\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 59ms/step - loss: -571042688.0000 - accuracy: 0.6656\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -572710592.0000 - accuracy: 0.6656\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -574336256.0000 - accuracy: 0.6656\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -576067648.0000 - accuracy: 0.6656\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -577719040.0000 - accuracy: 0.6656\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -579439104.0000 - accuracy: 0.6656\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -581067456.0000 - accuracy: 0.6656\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -582748864.0000 - accuracy: 0.6656\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -584448384.0000 - accuracy: 0.6656\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -586091264.0000 - accuracy: 0.6656\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -587731840.0000 - accuracy: 0.6656\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 30ms/step - loss: -589439744.0000 - accuracy: 0.6656\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -591105920.0000 - accuracy: 0.6656\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 32ms/step - loss: -592793600.0000 - accuracy: 0.6656\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 31ms/step - loss: -594453440.0000 - accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249088ae8b0>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, y_train_preprocessed, epochs=300, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 14ms/step - loss: -567100224.0000 - accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_pad, y_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.06%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.33999345, 0.6600065 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999258, 0.66000736],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999622, 0.6600037 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399943 , 0.6600057 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399941 , 0.6600059 ],\n",
       "       [0.34000266, 0.65999734],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399939 , 0.6600061 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999622, 0.6600037 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999646, 0.66000354],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999622, 0.6600037 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999708, 0.6600029 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.33999473, 0.66000533],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.33999497, 0.66000503],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999366, 0.66000634],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999622, 0.6600037 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399943 , 0.6600057 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399943 , 0.6600057 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.33999473, 0.66000533],\n",
       "       [0.33999473, 0.66000533],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399911 , 0.66000897],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.34000245, 0.6599976 ],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999237, 0.6600076 ],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999455, 0.66000545],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999044, 0.66000956],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999237, 0.6600076 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.3399956 , 0.66000444],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.33999518, 0.66000485],\n",
       "       [0.3399958 , 0.66000414],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.339996  , 0.66000396],\n",
       "       [0.33999538, 0.6600046 ],\n",
       "       [0.3399958 , 0.66000414]], dtype=float32)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -596119104.0000 - accuracy: 0.6656 - val_loss: -568697920.0000 - val_accuracy: 0.6806\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -597749312.0000 - accuracy: 0.6656 - val_loss: -570318272.0000 - val_accuracy: 0.6806\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 0s 48ms/step - loss: -599502976.0000 - accuracy: 0.6656 - val_loss: -571892800.0000 - val_accuracy: 0.6806\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -601160256.0000 - accuracy: 0.6656 - val_loss: -573476416.0000 - val_accuracy: 0.6806\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -602861376.0000 - accuracy: 0.6656 - val_loss: -575044032.0000 - val_accuracy: 0.6806\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -604494464.0000 - accuracy: 0.6656 - val_loss: -576636032.0000 - val_accuracy: 0.6806\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -606133952.0000 - accuracy: 0.6656 - val_loss: -578247104.0000 - val_accuracy: 0.6806\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -607822400.0000 - accuracy: 0.6656 - val_loss: -579848128.0000 - val_accuracy: 0.6806\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -609508160.0000 - accuracy: 0.6656 - val_loss: -581441344.0000 - val_accuracy: 0.6806\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -611167552.0000 - accuracy: 0.6656 - val_loss: -583041728.0000 - val_accuracy: 0.6806\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -612864640.0000 - accuracy: 0.6656 - val_loss: -584627968.0000 - val_accuracy: 0.6806\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -614546432.0000 - accuracy: 0.6656 - val_loss: -586208896.0000 - val_accuracy: 0.6806\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -616195136.0000 - accuracy: 0.6656 - val_loss: -587803584.0000 - val_accuracy: 0.6806\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -617870976.0000 - accuracy: 0.6656 - val_loss: -589396416.0000 - val_accuracy: 0.6806\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -619548224.0000 - accuracy: 0.6656 - val_loss: -590986304.0000 - val_accuracy: 0.6806\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -621210176.0000 - accuracy: 0.6656 - val_loss: -592582976.0000 - val_accuracy: 0.6806\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -622902208.0000 - accuracy: 0.6656 - val_loss: -594169472.0000 - val_accuracy: 0.6806\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -624585152.0000 - accuracy: 0.6656 - val_loss: -595750912.0000 - val_accuracy: 0.6806\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -626215552.0000 - accuracy: 0.6656 - val_loss: -597356864.0000 - val_accuracy: 0.6806\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -627903232.0000 - accuracy: 0.6656 - val_loss: -598953920.0000 - val_accuracy: 0.6806\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -629603520.0000 - accuracy: 0.6656 - val_loss: -600535296.0000 - val_accuracy: 0.6806\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -631220480.0000 - accuracy: 0.6656 - val_loss: -602147584.0000 - val_accuracy: 0.6806\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -632943168.0000 - accuracy: 0.6656 - val_loss: -603731328.0000 - val_accuracy: 0.6806\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -634590080.0000 - accuracy: 0.6656 - val_loss: -605329344.0000 - val_accuracy: 0.6806\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -636303744.0000 - accuracy: 0.6656 - val_loss: -606903360.0000 - val_accuracy: 0.6806\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -637948352.0000 - accuracy: 0.6656 - val_loss: -608493504.0000 - val_accuracy: 0.6806\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -639596096.0000 - accuracy: 0.6656 - val_loss: -610097664.0000 - val_accuracy: 0.6806\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -641283712.0000 - accuracy: 0.6656 - val_loss: -611693696.0000 - val_accuracy: 0.6806\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -642970112.0000 - accuracy: 0.6656 - val_loss: -613281600.0000 - val_accuracy: 0.6806\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -644598016.0000 - accuracy: 0.6656 - val_loss: -614894272.0000 - val_accuracy: 0.6806\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -646313216.0000 - accuracy: 0.6656 - val_loss: -616481600.0000 - val_accuracy: 0.6806\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -647991104.0000 - accuracy: 0.6656 - val_loss: -618065216.0000 - val_accuracy: 0.6806\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -649651840.0000 - accuracy: 0.6656 - val_loss: -619655488.0000 - val_accuracy: 0.6806\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -651325696.0000 - accuracy: 0.6656 - val_loss: -621244160.0000 - val_accuracy: 0.6806\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -653000192.0000 - accuracy: 0.6656 - val_loss: -622831424.0000 - val_accuracy: 0.6806\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -654696256.0000 - accuracy: 0.6656 - val_loss: -624404992.0000 - val_accuracy: 0.6806\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -656334784.0000 - accuracy: 0.6656 - val_loss: -625998592.0000 - val_accuracy: 0.6806\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -657995968.0000 - accuracy: 0.6656 - val_loss: -627598912.0000 - val_accuracy: 0.6806\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -659628352.0000 - accuracy: 0.6656 - val_loss: -629220416.0000 - val_accuracy: 0.6806\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -661398528.0000 - accuracy: 0.6656 - val_loss: -630785728.0000 - val_accuracy: 0.6806\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -662980096.0000 - accuracy: 0.6656 - val_loss: -632402432.0000 - val_accuracy: 0.6806\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -664730624.0000 - accuracy: 0.6656 - val_loss: -633973952.0000 - val_accuracy: 0.6806\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -666367552.0000 - accuracy: 0.6656 - val_loss: -635566016.0000 - val_accuracy: 0.6806\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -668039232.0000 - accuracy: 0.6656 - val_loss: -637158208.0000 - val_accuracy: 0.6806\n",
      "Epoch 45/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -669712704.0000 - accuracy: 0.6656 - val_loss: -638749632.0000 - val_accuracy: 0.6806\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -671371904.0000 - accuracy: 0.6656 - val_loss: -640347392.0000 - val_accuracy: 0.6806\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -673068416.0000 - accuracy: 0.6656 - val_loss: -641930880.0000 - val_accuracy: 0.6806\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -674705152.0000 - accuracy: 0.6656 - val_loss: -643534272.0000 - val_accuracy: 0.6806\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -676405440.0000 - accuracy: 0.6656 - val_loss: -645121216.0000 - val_accuracy: 0.6806\n",
      "Epoch 50/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -678081408.0000 - accuracy: 0.6656 - val_loss: -646704640.0000 - val_accuracy: 0.6806\n",
      "Epoch 51/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -679722368.0000 - accuracy: 0.6656 - val_loss: -648305088.0000 - val_accuracy: 0.6806\n",
      "Epoch 52/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -681405568.0000 - accuracy: 0.6656 - val_loss: -649898560.0000 - val_accuracy: 0.6806\n",
      "Epoch 53/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -683069376.0000 - accuracy: 0.6656 - val_loss: -651495872.0000 - val_accuracy: 0.6806\n",
      "Epoch 54/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -684752128.0000 - accuracy: 0.6656 - val_loss: -653086144.0000 - val_accuracy: 0.6806\n",
      "Epoch 55/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -686424768.0000 - accuracy: 0.6656 - val_loss: -654675840.0000 - val_accuracy: 0.6806\n",
      "Epoch 56/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -688125184.0000 - accuracy: 0.6656 - val_loss: -656248192.0000 - val_accuracy: 0.6806\n",
      "Epoch 57/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -689788800.0000 - accuracy: 0.6656 - val_loss: -657825216.0000 - val_accuracy: 0.6806\n",
      "Epoch 58/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -691449216.0000 - accuracy: 0.6656 - val_loss: -659408832.0000 - val_accuracy: 0.6806\n",
      "Epoch 59/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -693099264.0000 - accuracy: 0.6656 - val_loss: -661005056.0000 - val_accuracy: 0.6806\n",
      "Epoch 60/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -694773504.0000 - accuracy: 0.6656 - val_loss: -662600256.0000 - val_accuracy: 0.6806\n",
      "Epoch 61/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -696441024.0000 - accuracy: 0.6656 - val_loss: -664198272.0000 - val_accuracy: 0.6806\n",
      "Epoch 62/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -698112704.0000 - accuracy: 0.6656 - val_loss: -665796096.0000 - val_accuracy: 0.6806\n",
      "Epoch 63/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -699783360.0000 - accuracy: 0.6656 - val_loss: -667393600.0000 - val_accuracy: 0.6806\n",
      "Epoch 64/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -701452224.0000 - accuracy: 0.6656 - val_loss: -668991232.0000 - val_accuracy: 0.6806\n",
      "Epoch 65/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -703134272.0000 - accuracy: 0.6656 - val_loss: -670582016.0000 - val_accuracy: 0.6806\n",
      "Epoch 66/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -704805056.0000 - accuracy: 0.6656 - val_loss: -672172864.0000 - val_accuracy: 0.6806\n",
      "Epoch 67/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -706467776.0000 - accuracy: 0.6656 - val_loss: -673768384.0000 - val_accuracy: 0.6806\n",
      "Epoch 68/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -708133248.0000 - accuracy: 0.6656 - val_loss: -675367040.0000 - val_accuracy: 0.6806\n",
      "Epoch 69/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -709829888.0000 - accuracy: 0.6656 - val_loss: -676950144.0000 - val_accuracy: 0.6806\n",
      "Epoch 70/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -711510656.0000 - accuracy: 0.6656 - val_loss: -678527488.0000 - val_accuracy: 0.6806\n",
      "Epoch 71/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -713182016.0000 - accuracy: 0.6656 - val_loss: -680104704.0000 - val_accuracy: 0.6806\n",
      "Epoch 72/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -714818368.0000 - accuracy: 0.6656 - val_loss: -681701696.0000 - val_accuracy: 0.6806\n",
      "Epoch 73/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -716502848.0000 - accuracy: 0.6656 - val_loss: -683291008.0000 - val_accuracy: 0.6806\n",
      "Epoch 74/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -718163584.0000 - accuracy: 0.6656 - val_loss: -684886528.0000 - val_accuracy: 0.6806\n",
      "Epoch 75/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -719845952.0000 - accuracy: 0.6656 - val_loss: -686475008.0000 - val_accuracy: 0.6806\n",
      "Epoch 76/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -721509952.0000 - accuracy: 0.6656 - val_loss: -688067264.0000 - val_accuracy: 0.6806\n",
      "Epoch 77/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -723196288.0000 - accuracy: 0.6656 - val_loss: -689650752.0000 - val_accuracy: 0.6806\n",
      "Epoch 78/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -724828160.0000 - accuracy: 0.6656 - val_loss: -691256256.0000 - val_accuracy: 0.6806\n",
      "Epoch 79/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -726502912.0000 - accuracy: 0.6656 - val_loss: -692858688.0000 - val_accuracy: 0.6806\n",
      "Epoch 80/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -728205440.0000 - accuracy: 0.6656 - val_loss: -694443072.0000 - val_accuracy: 0.6806\n",
      "Epoch 81/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -729861056.0000 - accuracy: 0.6656 - val_loss: -696035648.0000 - val_accuracy: 0.6806\n",
      "Epoch 82/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -731529280.0000 - accuracy: 0.6656 - val_loss: -697628544.0000 - val_accuracy: 0.6806\n",
      "Epoch 83/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -733193088.0000 - accuracy: 0.6656 - val_loss: -699224384.0000 - val_accuracy: 0.6806\n",
      "Epoch 84/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -734905408.0000 - accuracy: 0.6656 - val_loss: -700796032.0000 - val_accuracy: 0.6806\n",
      "Epoch 85/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -736527360.0000 - accuracy: 0.6656 - val_loss: -702394880.0000 - val_accuracy: 0.6806\n",
      "Epoch 86/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -738202240.0000 - accuracy: 0.6656 - val_loss: -703990400.0000 - val_accuracy: 0.6806\n",
      "Epoch 87/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -739912256.0000 - accuracy: 0.6656 - val_loss: -705562624.0000 - val_accuracy: 0.6806\n",
      "Epoch 88/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -741537600.0000 - accuracy: 0.6656 - val_loss: -707160320.0000 - val_accuracy: 0.6806\n",
      "Epoch 89/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -743225408.0000 - accuracy: 0.6656 - val_loss: -708747200.0000 - val_accuracy: 0.6806\n",
      "Epoch 90/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -744894272.0000 - accuracy: 0.6656 - val_loss: -710334400.0000 - val_accuracy: 0.6806\n",
      "Epoch 91/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -746544768.0000 - accuracy: 0.6656 - val_loss: -711932864.0000 - val_accuracy: 0.6806\n",
      "Epoch 92/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -748257088.0000 - accuracy: 0.6656 - val_loss: -713507136.0000 - val_accuracy: 0.6806\n",
      "Epoch 93/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -749897664.0000 - accuracy: 0.6656 - val_loss: -715098880.0000 - val_accuracy: 0.6806\n",
      "Epoch 94/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -751570048.0000 - accuracy: 0.6656 - val_loss: -716688896.0000 - val_accuracy: 0.6806\n",
      "Epoch 95/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -753184512.0000 - accuracy: 0.6656 - val_loss: -718308288.0000 - val_accuracy: 0.6806\n",
      "Epoch 96/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -754937152.0000 - accuracy: 0.6656 - val_loss: -719881216.0000 - val_accuracy: 0.6806\n",
      "Epoch 97/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -756618240.0000 - accuracy: 0.6656 - val_loss: -721447168.0000 - val_accuracy: 0.6806\n",
      "Epoch 98/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -758237120.0000 - accuracy: 0.6656 - val_loss: -723042624.0000 - val_accuracy: 0.6806\n",
      "Epoch 99/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -759912896.0000 - accuracy: 0.6656 - val_loss: -724634624.0000 - val_accuracy: 0.6806\n",
      "Epoch 100/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -761566592.0000 - accuracy: 0.6656 - val_loss: -726234752.0000 - val_accuracy: 0.6806\n",
      "Epoch 101/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -763260544.0000 - accuracy: 0.6656 - val_loss: -727821056.0000 - val_accuracy: 0.6806\n",
      "Epoch 102/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -764930688.0000 - accuracy: 0.6656 - val_loss: -729407104.0000 - val_accuracy: 0.6806\n",
      "Epoch 103/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -766606848.0000 - accuracy: 0.6656 - val_loss: -730990016.0000 - val_accuracy: 0.6806\n",
      "Epoch 104/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -768275712.0000 - accuracy: 0.6656 - val_loss: -732574272.0000 - val_accuracy: 0.6806\n",
      "Epoch 105/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -769947520.0000 - accuracy: 0.6656 - val_loss: -734157504.0000 - val_accuracy: 0.6806\n",
      "Epoch 106/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -771585792.0000 - accuracy: 0.6656 - val_loss: -735758720.0000 - val_accuracy: 0.6806\n",
      "Epoch 107/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -773242880.0000 - accuracy: 0.6656 - val_loss: -737366016.0000 - val_accuracy: 0.6806\n",
      "Epoch 108/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -774923392.0000 - accuracy: 0.6656 - val_loss: -738966784.0000 - val_accuracy: 0.6806\n",
      "Epoch 109/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -776651776.0000 - accuracy: 0.6656 - val_loss: -740533120.0000 - val_accuracy: 0.6806\n",
      "Epoch 110/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -778288576.0000 - accuracy: 0.6656 - val_loss: -742119040.0000 - val_accuracy: 0.6806\n",
      "Epoch 111/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -779961856.0000 - accuracy: 0.6656 - val_loss: -743703360.0000 - val_accuracy: 0.6806\n",
      "Epoch 112/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -781644672.0000 - accuracy: 0.6656 - val_loss: -745280768.0000 - val_accuracy: 0.6806\n",
      "Epoch 113/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -783270336.0000 - accuracy: 0.6656 - val_loss: -746884096.0000 - val_accuracy: 0.6806\n",
      "Epoch 114/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -784962944.0000 - accuracy: 0.6656 - val_loss: -748474496.0000 - val_accuracy: 0.6806\n",
      "Epoch 115/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -786628096.0000 - accuracy: 0.6656 - val_loss: -750067648.0000 - val_accuracy: 0.6806\n",
      "Epoch 116/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -788312640.0000 - accuracy: 0.6656 - val_loss: -751651968.0000 - val_accuracy: 0.6806\n",
      "Epoch 117/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -789979840.0000 - accuracy: 0.6656 - val_loss: -753237824.0000 - val_accuracy: 0.6806\n",
      "Epoch 118/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -791639552.0000 - accuracy: 0.6656 - val_loss: -754830016.0000 - val_accuracy: 0.6806\n",
      "Epoch 119/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -793299072.0000 - accuracy: 0.6656 - val_loss: -756428288.0000 - val_accuracy: 0.6806\n",
      "Epoch 120/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -794939840.0000 - accuracy: 0.6656 - val_loss: -758041984.0000 - val_accuracy: 0.6806\n",
      "Epoch 121/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -796660352.0000 - accuracy: 0.6656 - val_loss: -759627008.0000 - val_accuracy: 0.6806\n",
      "Epoch 122/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -798307712.0000 - accuracy: 0.6656 - val_loss: -761224128.0000 - val_accuracy: 0.6806\n",
      "Epoch 123/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -799986432.0000 - accuracy: 0.6656 - val_loss: -762815360.0000 - val_accuracy: 0.6806\n",
      "Epoch 124/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -801697408.0000 - accuracy: 0.6656 - val_loss: -764382400.0000 - val_accuracy: 0.6806\n",
      "Epoch 125/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -803337472.0000 - accuracy: 0.6656 - val_loss: -765966400.0000 - val_accuracy: 0.6806\n",
      "Epoch 126/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -804987456.0000 - accuracy: 0.6656 - val_loss: -767561728.0000 - val_accuracy: 0.6806\n",
      "Epoch 127/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -806698432.0000 - accuracy: 0.6656 - val_loss: -769133056.0000 - val_accuracy: 0.6806\n",
      "Epoch 128/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -808293248.0000 - accuracy: 0.6656 - val_loss: -770746944.0000 - val_accuracy: 0.6806\n",
      "Epoch 129/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -809983936.0000 - accuracy: 0.6656 - val_loss: -772347840.0000 - val_accuracy: 0.6806\n",
      "Epoch 130/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -811674496.0000 - accuracy: 0.6656 - val_loss: -773936128.0000 - val_accuracy: 0.6806\n",
      "Epoch 131/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -813352192.0000 - accuracy: 0.6656 - val_loss: -775519424.0000 - val_accuracy: 0.6806\n",
      "Epoch 132/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -815011584.0000 - accuracy: 0.6656 - val_loss: -777107904.0000 - val_accuracy: 0.6806\n",
      "Epoch 133/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -816680704.0000 - accuracy: 0.6656 - val_loss: -778696000.0000 - val_accuracy: 0.6806\n",
      "Epoch 134/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -818370048.0000 - accuracy: 0.6656 - val_loss: -780272448.0000 - val_accuracy: 0.6806\n",
      "Epoch 135/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -819982912.0000 - accuracy: 0.6656 - val_loss: -781880192.0000 - val_accuracy: 0.6806\n",
      "Epoch 136/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -821693312.0000 - accuracy: 0.6656 - val_loss: -783464512.0000 - val_accuracy: 0.6806\n",
      "Epoch 137/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -823335232.0000 - accuracy: 0.6656 - val_loss: -785063808.0000 - val_accuracy: 0.6806\n",
      "Epoch 138/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -825044992.0000 - accuracy: 0.6656 - val_loss: -786639616.0000 - val_accuracy: 0.6806\n",
      "Epoch 139/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -826695104.0000 - accuracy: 0.6656 - val_loss: -788226240.0000 - val_accuracy: 0.6806\n",
      "Epoch 140/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -828361216.0000 - accuracy: 0.6656 - val_loss: -789814464.0000 - val_accuracy: 0.6806\n",
      "Epoch 141/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -829996288.0000 - accuracy: 0.6656 - val_loss: -791420992.0000 - val_accuracy: 0.6806\n",
      "Epoch 142/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -831725120.0000 - accuracy: 0.6656 - val_loss: -792993152.0000 - val_accuracy: 0.6806\n",
      "Epoch 143/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -833353600.0000 - accuracy: 0.6656 - val_loss: -794588224.0000 - val_accuracy: 0.6806\n",
      "Epoch 144/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -835050944.0000 - accuracy: 0.6656 - val_loss: -796166656.0000 - val_accuracy: 0.6806\n",
      "Epoch 145/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -836672128.0000 - accuracy: 0.6656 - val_loss: -797771520.0000 - val_accuracy: 0.6806\n",
      "Epoch 146/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -838393408.0000 - accuracy: 0.6656 - val_loss: -799347072.0000 - val_accuracy: 0.6806\n",
      "Epoch 147/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -840067904.0000 - accuracy: 0.6656 - val_loss: -800919680.0000 - val_accuracy: 0.6806\n",
      "Epoch 148/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -841676800.0000 - accuracy: 0.6656 - val_loss: -802526400.0000 - val_accuracy: 0.6806\n",
      "Epoch 149/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -843388544.0000 - accuracy: 0.6656 - val_loss: -804109248.0000 - val_accuracy: 0.6806\n",
      "Epoch 150/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -845041536.0000 - accuracy: 0.6656 - val_loss: -805700928.0000 - val_accuracy: 0.6806\n",
      "Epoch 151/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -846716864.0000 - accuracy: 0.6656 - val_loss: -807289408.0000 - val_accuracy: 0.6806\n",
      "Epoch 152/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -848388928.0000 - accuracy: 0.6656 - val_loss: -808876736.0000 - val_accuracy: 0.6806\n",
      "Epoch 153/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -850052672.0000 - accuracy: 0.6656 - val_loss: -810467008.0000 - val_accuracy: 0.6806\n",
      "Epoch 154/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -851735616.0000 - accuracy: 0.6656 - val_loss: -812049344.0000 - val_accuracy: 0.6806\n",
      "Epoch 155/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -853403328.0000 - accuracy: 0.6656 - val_loss: -813632896.0000 - val_accuracy: 0.6806\n",
      "Epoch 156/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -855098688.0000 - accuracy: 0.6656 - val_loss: -815202560.0000 - val_accuracy: 0.6806\n",
      "Epoch 157/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -856705792.0000 - accuracy: 0.6656 - val_loss: -816808704.0000 - val_accuracy: 0.6806\n",
      "Epoch 158/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -858407424.0000 - accuracy: 0.6656 - val_loss: -818396928.0000 - val_accuracy: 0.6806\n",
      "Epoch 159/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -860064128.0000 - accuracy: 0.6656 - val_loss: -819992640.0000 - val_accuracy: 0.6806\n",
      "Epoch 160/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -861745024.0000 - accuracy: 0.6656 - val_loss: -821581888.0000 - val_accuracy: 0.6806\n",
      "Epoch 161/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -863420224.0000 - accuracy: 0.6656 - val_loss: -823168000.0000 - val_accuracy: 0.6806\n",
      "Epoch 162/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -865052800.0000 - accuracy: 0.6656 - val_loss: -824774912.0000 - val_accuracy: 0.6806\n",
      "Epoch 163/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -866765440.0000 - accuracy: 0.6656 - val_loss: -826357312.0000 - val_accuracy: 0.6806\n",
      "Epoch 164/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -868408000.0000 - accuracy: 0.6656 - val_loss: -827954368.0000 - val_accuracy: 0.6806\n",
      "Epoch 165/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -870108864.0000 - accuracy: 0.6656 - val_loss: -829533824.0000 - val_accuracy: 0.6806\n",
      "Epoch 166/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -871736896.0000 - accuracy: 0.6656 - val_loss: -831136192.0000 - val_accuracy: 0.6806\n",
      "Epoch 167/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -873388864.0000 - accuracy: 0.6656 - val_loss: -832747264.0000 - val_accuracy: 0.6806\n",
      "Epoch 168/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -875112384.0000 - accuracy: 0.6656 - val_loss: -834327680.0000 - val_accuracy: 0.6806\n",
      "Epoch 169/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -876797888.0000 - accuracy: 0.6656 - val_loss: -835899328.0000 - val_accuracy: 0.6806\n",
      "Epoch 170/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -878437184.0000 - accuracy: 0.6656 - val_loss: -837488128.0000 - val_accuracy: 0.6806\n",
      "Epoch 171/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -880139072.0000 - accuracy: 0.6656 - val_loss: -839058752.0000 - val_accuracy: 0.6806\n",
      "Epoch 172/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -881783040.0000 - accuracy: 0.6656 - val_loss: -840644800.0000 - val_accuracy: 0.6806\n",
      "Epoch 173/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -883411648.0000 - accuracy: 0.6656 - val_loss: -842253120.0000 - val_accuracy: 0.6806\n",
      "Epoch 174/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -885116864.0000 - accuracy: 0.6656 - val_loss: -843842368.0000 - val_accuracy: 0.6806\n",
      "Epoch 175/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -886789504.0000 - accuracy: 0.6656 - val_loss: -845429504.0000 - val_accuracy: 0.6806\n",
      "Epoch 176/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -888416640.0000 - accuracy: 0.6656 - val_loss: -847038912.0000 - val_accuracy: 0.6806\n",
      "Epoch 177/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -890147072.0000 - accuracy: 0.6656 - val_loss: -848613504.0000 - val_accuracy: 0.6806\n",
      "Epoch 178/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -891770944.0000 - accuracy: 0.6656 - val_loss: -850213376.0000 - val_accuracy: 0.6806\n",
      "Epoch 179/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -893472384.0000 - accuracy: 0.6656 - val_loss: -851795072.0000 - val_accuracy: 0.6806\n",
      "Epoch 180/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -895151488.0000 - accuracy: 0.6656 - val_loss: -853371008.0000 - val_accuracy: 0.6806\n",
      "Epoch 181/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -896815552.0000 - accuracy: 0.6656 - val_loss: -854948928.0000 - val_accuracy: 0.6806\n",
      "Epoch 182/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -898478144.0000 - accuracy: 0.6656 - val_loss: -856531072.0000 - val_accuracy: 0.6806\n",
      "Epoch 183/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -900120256.0000 - accuracy: 0.6656 - val_loss: -858128704.0000 - val_accuracy: 0.6806\n",
      "Epoch 184/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -901801600.0000 - accuracy: 0.6656 - val_loss: -859719424.0000 - val_accuracy: 0.6806\n",
      "Epoch 185/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -903462400.0000 - accuracy: 0.6656 - val_loss: -861314624.0000 - val_accuracy: 0.6806\n",
      "Epoch 186/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -905123072.0000 - accuracy: 0.6656 - val_loss: -862913728.0000 - val_accuracy: 0.6806\n",
      "Epoch 187/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -906825920.0000 - accuracy: 0.6656 - val_loss: -864493440.0000 - val_accuracy: 0.6806\n",
      "Epoch 188/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -908467392.0000 - accuracy: 0.6656 - val_loss: -866088320.0000 - val_accuracy: 0.6806\n",
      "Epoch 189/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -910143552.0000 - accuracy: 0.6656 - val_loss: -867678656.0000 - val_accuracy: 0.6806\n",
      "Epoch 190/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -911814016.0000 - accuracy: 0.6656 - val_loss: -869267904.0000 - val_accuracy: 0.6806\n",
      "Epoch 191/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -913449088.0000 - accuracy: 0.6656 - val_loss: -870874304.0000 - val_accuracy: 0.6806\n",
      "Epoch 192/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -915183040.0000 - accuracy: 0.6656 - val_loss: -872444160.0000 - val_accuracy: 0.6806\n",
      "Epoch 193/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -916838272.0000 - accuracy: 0.6656 - val_loss: -874021888.0000 - val_accuracy: 0.6806\n",
      "Epoch 194/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -918491392.0000 - accuracy: 0.6656 - val_loss: -875608832.0000 - val_accuracy: 0.6806\n",
      "Epoch 195/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -920141312.0000 - accuracy: 0.6656 - val_loss: -877205952.0000 - val_accuracy: 0.6806\n",
      "Epoch 196/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -921782208.0000 - accuracy: 0.6656 - val_loss: -878816832.0000 - val_accuracy: 0.6806\n",
      "Epoch 197/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -923503808.0000 - accuracy: 0.6656 - val_loss: -880397760.0000 - val_accuracy: 0.6806\n",
      "Epoch 198/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -925171456.0000 - accuracy: 0.6656 - val_loss: -881979712.0000 - val_accuracy: 0.6806\n",
      "Epoch 199/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -926830528.0000 - accuracy: 0.6656 - val_loss: -883566976.0000 - val_accuracy: 0.6806\n",
      "Epoch 200/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -928514240.0000 - accuracy: 0.6656 - val_loss: -885145920.0000 - val_accuracy: 0.6806\n",
      "Epoch 201/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -930143168.0000 - accuracy: 0.6656 - val_loss: -886746880.0000 - val_accuracy: 0.6806\n",
      "Epoch 202/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -931851584.0000 - accuracy: 0.6656 - val_loss: -888324352.0000 - val_accuracy: 0.6806\n",
      "Epoch 203/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -933498560.0000 - accuracy: 0.6656 - val_loss: -889913664.0000 - val_accuracy: 0.6806\n",
      "Epoch 204/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -935152384.0000 - accuracy: 0.6656 - val_loss: -891510912.0000 - val_accuracy: 0.6806\n",
      "Epoch 205/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -936843840.0000 - accuracy: 0.6656 - val_loss: -893095040.0000 - val_accuracy: 0.6806\n",
      "Epoch 206/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -938508736.0000 - accuracy: 0.6656 - val_loss: -894681280.0000 - val_accuracy: 0.6806\n",
      "Epoch 207/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -940157824.0000 - accuracy: 0.6656 - val_loss: -896278080.0000 - val_accuracy: 0.6806\n",
      "Epoch 208/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -941830912.0000 - accuracy: 0.6656 - val_loss: -897871360.0000 - val_accuracy: 0.6806\n",
      "Epoch 209/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -943526080.0000 - accuracy: 0.6656 - val_loss: -899449024.0000 - val_accuracy: 0.6806\n",
      "Epoch 210/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -945156160.0000 - accuracy: 0.6656 - val_loss: -901046720.0000 - val_accuracy: 0.6806\n",
      "Epoch 211/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -946858560.0000 - accuracy: 0.6656 - val_loss: -902625280.0000 - val_accuracy: 0.6806\n",
      "Epoch 212/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -948522752.0000 - accuracy: 0.6656 - val_loss: -904205952.0000 - val_accuracy: 0.6806\n",
      "Epoch 213/300\n",
      "6/6 [==============================] - 0s 39ms/step - loss: -950189824.0000 - accuracy: 0.6656 - val_loss: -905787456.0000 - val_accuracy: 0.6806\n",
      "Epoch 214/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -951868352.0000 - accuracy: 0.6656 - val_loss: -907362560.0000 - val_accuracy: 0.6806\n",
      "Epoch 215/300\n",
      "6/6 [==============================] - 0s 47ms/step - loss: -953527296.0000 - accuracy: 0.6656 - val_loss: -908943680.0000 - val_accuracy: 0.6806\n",
      "Epoch 216/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -955169856.0000 - accuracy: 0.6656 - val_loss: -910539584.0000 - val_accuracy: 0.6806\n",
      "Epoch 217/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -956841408.0000 - accuracy: 0.6656 - val_loss: -912133504.0000 - val_accuracy: 0.6806\n",
      "Epoch 218/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -958530240.0000 - accuracy: 0.6656 - val_loss: -913715968.0000 - val_accuracy: 0.6806\n",
      "Epoch 219/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -960179584.0000 - accuracy: 0.6656 - val_loss: -915309632.0000 - val_accuracy: 0.6806\n",
      "Epoch 220/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -961848512.0000 - accuracy: 0.6656 - val_loss: -916902528.0000 - val_accuracy: 0.6806\n",
      "Epoch 221/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -963507776.0000 - accuracy: 0.6656 - val_loss: -918499200.0000 - val_accuracy: 0.6806\n",
      "Epoch 222/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -965179648.0000 - accuracy: 0.6656 - val_loss: -920093696.0000 - val_accuracy: 0.6806\n",
      "Epoch 223/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -966869184.0000 - accuracy: 0.6656 - val_loss: -921675456.0000 - val_accuracy: 0.6806\n",
      "Epoch 224/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -968536832.0000 - accuracy: 0.6656 - val_loss: -923257280.0000 - val_accuracy: 0.6806\n",
      "Epoch 225/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -970185920.0000 - accuracy: 0.6656 - val_loss: -924849536.0000 - val_accuracy: 0.6806\n",
      "Epoch 226/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -971884288.0000 - accuracy: 0.6656 - val_loss: -926424512.0000 - val_accuracy: 0.6806\n",
      "Epoch 227/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -973537280.0000 - accuracy: 0.6656 - val_loss: -928008576.0000 - val_accuracy: 0.6806\n",
      "Epoch 228/300\n",
      "6/6 [==============================] - 0s 38ms/step - loss: -975172608.0000 - accuracy: 0.6656 - val_loss: -929612032.0000 - val_accuracy: 0.6806\n",
      "Epoch 229/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -976881088.0000 - accuracy: 0.6656 - val_loss: -931192704.0000 - val_accuracy: 0.6806\n",
      "Epoch 230/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -978498816.0000 - accuracy: 0.6656 - val_loss: -932801152.0000 - val_accuracy: 0.6806\n",
      "Epoch 231/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -980188864.0000 - accuracy: 0.6656 - val_loss: -934396352.0000 - val_accuracy: 0.6806\n",
      "Epoch 232/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -981867648.0000 - accuracy: 0.6656 - val_loss: -935985344.0000 - val_accuracy: 0.6806\n",
      "Epoch 233/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -983562752.0000 - accuracy: 0.6656 - val_loss: -937558848.0000 - val_accuracy: 0.6806\n",
      "Epoch 234/300\n",
      "6/6 [==============================] - 0s 44ms/step - loss: -985233408.0000 - accuracy: 0.6656 - val_loss: -939131072.0000 - val_accuracy: 0.6806\n",
      "Epoch 235/300\n",
      "6/6 [==============================] - 0s 46ms/step - loss: -986859456.0000 - accuracy: 0.6656 - val_loss: -940727680.0000 - val_accuracy: 0.6806\n",
      "Epoch 236/300\n",
      "6/6 [==============================] - 0s 49ms/step - loss: -988524416.0000 - accuracy: 0.6656 - val_loss: -942325440.0000 - val_accuracy: 0.6806\n",
      "Epoch 237/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -990221184.0000 - accuracy: 0.6656 - val_loss: -943906624.0000 - val_accuracy: 0.6806\n",
      "Epoch 238/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -991867264.0000 - accuracy: 0.6656 - val_loss: -945499712.0000 - val_accuracy: 0.6806\n",
      "Epoch 239/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: -993554816.0000 - accuracy: 0.6656 - val_loss: -947082112.0000 - val_accuracy: 0.6806\n",
      "Epoch 240/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -995237952.0000 - accuracy: 0.6656 - val_loss: -948655616.0000 - val_accuracy: 0.6806\n",
      "Epoch 241/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -996849024.0000 - accuracy: 0.6656 - val_loss: -950261504.0000 - val_accuracy: 0.6806\n",
      "Epoch 242/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -998554816.0000 - accuracy: 0.6656 - val_loss: -951845184.0000 - val_accuracy: 0.6806\n",
      "Epoch 243/300\n",
      "6/6 [==============================] - 0s 42ms/step - loss: -1000193984.0000 - accuracy: 0.6656 - val_loss: -953444992.0000 - val_accuracy: 0.6806\n",
      "Epoch 244/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -1001910656.0000 - accuracy: 0.6656 - val_loss: -955017280.0000 - val_accuracy: 0.6806\n",
      "Epoch 245/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -1003556608.0000 - accuracy: 0.6656 - val_loss: -956602432.0000 - val_accuracy: 0.6806\n",
      "Epoch 246/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -1005221696.0000 - accuracy: 0.6656 - val_loss: -958189504.0000 - val_accuracy: 0.6806\n",
      "Epoch 247/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -1006862784.0000 - accuracy: 0.6656 - val_loss: -959791552.0000 - val_accuracy: 0.6806\n",
      "Epoch 248/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -1008569856.0000 - accuracy: 0.6656 - val_loss: -961371264.0000 - val_accuracy: 0.6806\n",
      "Epoch 249/300\n",
      "6/6 [==============================] - 0s 67ms/step - loss: -1010219200.0000 - accuracy: 0.6656 - val_loss: -962961472.0000 - val_accuracy: 0.6806\n",
      "Epoch 250/300\n",
      "6/6 [==============================] - 0s 66ms/step - loss: -1011881920.0000 - accuracy: 0.6656 - val_loss: -964554048.0000 - val_accuracy: 0.6806\n",
      "Epoch 251/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -1013554752.0000 - accuracy: 0.6656 - val_loss: -966143616.0000 - val_accuracy: 0.6806\n",
      "Epoch 252/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -1015246976.0000 - accuracy: 0.6656 - val_loss: -967720192.0000 - val_accuracy: 0.6806\n",
      "Epoch 253/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -1016905536.0000 - accuracy: 0.6656 - val_loss: -969302464.0000 - val_accuracy: 0.6806\n",
      "Epoch 254/300\n",
      "6/6 [==============================] - 0s 56ms/step - loss: -1018563968.0000 - accuracy: 0.6656 - val_loss: -970890816.0000 - val_accuracy: 0.6806\n",
      "Epoch 255/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -1020260928.0000 - accuracy: 0.6656 - val_loss: -972462208.0000 - val_accuracy: 0.6806\n",
      "Epoch 256/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -1021861504.0000 - accuracy: 0.6656 - val_loss: -974071680.0000 - val_accuracy: 0.6806\n",
      "Epoch 257/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -1023565632.0000 - accuracy: 0.6656 - val_loss: -975660864.0000 - val_accuracy: 0.6806\n",
      "Epoch 258/300\n",
      "6/6 [==============================] - 0s 41ms/step - loss: -1025229056.0000 - accuracy: 0.6656 - val_loss: -977252096.0000 - val_accuracy: 0.6806\n",
      "Epoch 259/300\n",
      "6/6 [==============================] - 0s 43ms/step - loss: -1026886592.0000 - accuracy: 0.6656 - val_loss: -978848896.0000 - val_accuracy: 0.6806\n",
      "Epoch 260/300\n",
      "6/6 [==============================] - 0s 65ms/step - loss: -1028550720.0000 - accuracy: 0.6656 - val_loss: -980447040.0000 - val_accuracy: 0.6806\n",
      "Epoch 261/300\n",
      "6/6 [==============================] - 0s 40ms/step - loss: -1030254208.0000 - accuracy: 0.6656 - val_loss: -982025152.0000 - val_accuracy: 0.6806\n",
      "Epoch 262/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -1031917824.0000 - accuracy: 0.6656 - val_loss: -983605632.0000 - val_accuracy: 0.6806\n",
      "Epoch 263/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -1033619200.0000 - accuracy: 0.6656 - val_loss: -985167680.0000 - val_accuracy: 0.6806\n",
      "Epoch 264/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -1035220736.0000 - accuracy: 0.6656 - val_loss: -986769024.0000 - val_accuracy: 0.6806\n",
      "Epoch 265/300\n",
      "6/6 [==============================] - 0s 37ms/step - loss: -1036882368.0000 - accuracy: 0.6656 - val_loss: -988373824.0000 - val_accuracy: 0.6806\n",
      "Epoch 266/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -1038577472.0000 - accuracy: 0.6656 - val_loss: -989962688.0000 - val_accuracy: 0.6806\n",
      "Epoch 267/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -1040249408.0000 - accuracy: 0.6656 - val_loss: -991549056.0000 - val_accuracy: 0.6806\n",
      "Epoch 268/300\n",
      "6/6 [==============================] - 0s 35ms/step - loss: -1041893888.0000 - accuracy: 0.6656 - val_loss: -993147648.0000 - val_accuracy: 0.6806\n",
      "Epoch 269/300\n",
      "6/6 [==============================] - 0s 36ms/step - loss: -1043591040.0000 - accuracy: 0.6656 - val_loss: -994729600.0000 - val_accuracy: 0.6806\n",
      "Epoch 270/300\n",
      "6/6 [==============================] - 0s 45ms/step - loss: -1045292928.0000 - accuracy: 0.6656 - val_loss: -996293312.0000 - val_accuracy: 0.6806\n",
      "Epoch 271/300\n",
      "6/6 [==============================] - 0s 53ms/step - loss: -1046871232.0000 - accuracy: 0.6656 - val_loss: -997907584.0000 - val_accuracy: 0.6806\n",
      "Epoch 272/300\n",
      "6/6 [==============================] - 0s 56ms/step - loss: -1048588544.0000 - accuracy: 0.6656 - val_loss: -999494144.0000 - val_accuracy: 0.6806\n",
      "Epoch 273/300\n",
      "6/6 [==============================] - 0s 59ms/step - loss: -1050254144.0000 - accuracy: 0.6656 - val_loss: -1001081472.0000 - val_accuracy: 0.6806\n",
      "Epoch 274/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -1051954048.0000 - accuracy: 0.6656 - val_loss: -1002650432.0000 - val_accuracy: 0.6806\n",
      "Epoch 275/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -1053580224.0000 - accuracy: 0.6656 - val_loss: -1004243200.0000 - val_accuracy: 0.6806\n",
      "Epoch 276/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -1055250048.0000 - accuracy: 0.6656 - val_loss: -1005834944.0000 - val_accuracy: 0.6806\n",
      "Epoch 277/300\n",
      "6/6 [==============================] - 0s 51ms/step - loss: -1056916736.0000 - accuracy: 0.6656 - val_loss: -1007426240.0000 - val_accuracy: 0.6806\n",
      "Epoch 278/300\n",
      "6/6 [==============================] - 0s 50ms/step - loss: -1058627392.0000 - accuracy: 0.6656 - val_loss: -1008993088.0000 - val_accuracy: 0.6806\n",
      "Epoch 279/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: -1060256576.0000 - accuracy: 0.6656 - val_loss: -1010583360.0000 - val_accuracy: 0.6806\n",
      "Epoch 280/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -1061905216.0000 - accuracy: 0.6656 - val_loss: -1012184320.0000 - val_accuracy: 0.6806\n",
      "Epoch 281/300\n",
      "6/6 [==============================] - 0s 71ms/step - loss: -1063579520.0000 - accuracy: 0.6656 - val_loss: -1013781376.0000 - val_accuracy: 0.6806\n",
      "Epoch 282/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -1065255488.0000 - accuracy: 0.6656 - val_loss: -1015373248.0000 - val_accuracy: 0.6806\n",
      "Epoch 283/300\n",
      "6/6 [==============================] - 0s 55ms/step - loss: -1066947008.0000 - accuracy: 0.6656 - val_loss: -1016951104.0000 - val_accuracy: 0.6806\n",
      "Epoch 284/300\n",
      "6/6 [==============================] - 0s 59ms/step - loss: -1068613376.0000 - accuracy: 0.6656 - val_loss: -1018529792.0000 - val_accuracy: 0.6806\n",
      "Epoch 285/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -1070247488.0000 - accuracy: 0.6656 - val_loss: -1020127104.0000 - val_accuracy: 0.6806\n",
      "Epoch 286/300\n",
      "6/6 [==============================] - 0s 69ms/step - loss: -1071931584.0000 - accuracy: 0.6656 - val_loss: -1021715136.0000 - val_accuracy: 0.6806\n",
      "Epoch 287/300\n",
      "6/6 [==============================] - 0s 72ms/step - loss: -1073592064.0000 - accuracy: 0.6656 - val_loss: -1023306880.0000 - val_accuracy: 0.6806\n",
      "Epoch 288/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -1075263360.0000 - accuracy: 0.6656 - val_loss: -1024896064.0000 - val_accuracy: 0.6806\n",
      "Epoch 289/300\n",
      "6/6 [==============================] - 0s 54ms/step - loss: -1076958208.0000 - accuracy: 0.6656 - val_loss: -1026469952.0000 - val_accuracy: 0.6806\n",
      "Epoch 290/300\n",
      "6/6 [==============================] - 0s 72ms/step - loss: -1078582272.0000 - accuracy: 0.6656 - val_loss: -1028069120.0000 - val_accuracy: 0.6806\n",
      "Epoch 291/300\n",
      "6/6 [==============================] - 1s 93ms/step - loss: -1080253056.0000 - accuracy: 0.6656 - val_loss: -1029665536.0000 - val_accuracy: 0.6806\n",
      "Epoch 292/300\n",
      "6/6 [==============================] - 0s 70ms/step - loss: -1081975552.0000 - accuracy: 0.6656 - val_loss: -1031230400.0000 - val_accuracy: 0.6806\n",
      "Epoch 293/300\n",
      "6/6 [==============================] - 0s 66ms/step - loss: -1083613952.0000 - accuracy: 0.6656 - val_loss: -1032812864.0000 - val_accuracy: 0.6806\n",
      "Epoch 294/300\n",
      "6/6 [==============================] - 0s 74ms/step - loss: -1085232384.0000 - accuracy: 0.6656 - val_loss: -1034422272.0000 - val_accuracy: 0.6806\n",
      "Epoch 295/300\n",
      "6/6 [==============================] - 0s 69ms/step - loss: -1086933632.0000 - accuracy: 0.6656 - val_loss: -1036012288.0000 - val_accuracy: 0.6806\n",
      "Epoch 296/300\n",
      "6/6 [==============================] - 0s 63ms/step - loss: -1088613504.0000 - accuracy: 0.6656 - val_loss: -1037594688.0000 - val_accuracy: 0.6806\n",
      "Epoch 297/300\n",
      "6/6 [==============================] - 0s 66ms/step - loss: -1090290048.0000 - accuracy: 0.6656 - val_loss: -1039172288.0000 - val_accuracy: 0.6806\n",
      "Epoch 298/300\n",
      "6/6 [==============================] - 0s 71ms/step - loss: -1091932928.0000 - accuracy: 0.6656 - val_loss: -1040764032.0000 - val_accuracy: 0.6806\n",
      "Epoch 299/300\n",
      "6/6 [==============================] - 0s 75ms/step - loss: -1093592064.0000 - accuracy: 0.6656 - val_loss: -1042360576.0000 - val_accuracy: 0.6806\n",
      "Epoch 300/300\n",
      "6/6 [==============================] - 0s 60ms/step - loss: -1095305856.0000 - accuracy: 0.6656 - val_loss: -1043930240.0000 - val_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_pad, y_train_preprocessed, validation_data=(x_test_pad, y_test_preprocessed), epochs=300, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAGzCAYAAAAsQxMfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTi0lEQVR4nO3deVhUZf8G8HtAZgZkU1nFUVxwQREMgtDcKVIjLSu3BFGpXEqlRXlLUCsxLcPSNC21UtM0Nd80UknrVckFIzXQXFDEGBZJQFCWmef3hz9OjoAyiA547s91nUvnOc8553sOw8zNWRVCCAEiIiIimTIzdQFEREREpsQwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEdB8pFArMmjXL6OnOnz8PhUKB1atX13lNZBpjxoyBu7v7Hfv16dMHffr0uef1EMkZwxDJzurVq6FQKKBQKLBv375K44UQ0Gg0UCgUePLJJ01QIRER3U8MQyRbarUa69atq9T+yy+/ICMjAyqVygRVERHR/cYwRLI1cOBAbNy4EeXl5Qbt69atg6+vL1xcXExUmXwUFRWZugQiIoYhkq8RI0bg8uXL2LVrl9RWWlqKTZs2YeTIkVVOU1RUhNdeew0ajQYqlQodOnTABx98ACGEQb+SkhJMmzYNjo6OsLGxwVNPPYWMjIwq53np0iWMHTsWzs7OUKlU6Ny5M1auXFmrdcrLy8Prr78OLy8vWFtbw9bWFgMGDMAff/xRqe/169cxa9YstG/fHmq1Gq6urnjmmWdw9uxZqY9er8eiRYvg5eUFtVoNR0dHPPHEEzhy5AiA25/LdOv5UbNmzYJCoUBKSgpGjhyJJk2a4NFHHwUAHDt2DGPGjEGbNm2gVqvh4uKCsWPH4vLly1Vur3HjxqF58+ZQqVRo3bo1JkyYgNLSUpw7dw4KhQIfffRRpekOHDgAhUKBb775ptrtV1paiujoaPj6+sLOzg6NGzdGz549sWfPHoN+Fev9wQcfYPny5Wjbti1UKhUefvhhHD58uNJ8t27dii5dukCtVqNLly7YsmVLtTXURHZ2NsaNGwdnZ2eo1Wp4e3vjyy+/rNRv/fr18PX1hY2NDWxtbeHl5YVFixZJ48vKyjB79mx4eHhArVajWbNmePTRRw1+J4jkoJGpCyAyFXd3dwQGBuKbb77BgAEDAAA//vgj8vPzMXz4cHz88ccG/YUQeOqpp7Bnzx6MGzcOPj4++Omnn/DGG2/g0qVLBl/A48ePx5o1azBy5Eh0794dP//8MwYNGlSphqysLDzyyCNQKBSYPHkyHB0d8eOPP2LcuHEoKCjA1KlTjVqnc+fOYevWrXjuuefQunVrZGVl4bPPPkPv3r2RkpKC5s2bAwB0Oh2efPJJJCQkYPjw4ZgyZQoKCwuxa9cunDhxAm3btgUAjBs3DqtXr8aAAQMwfvx4lJeX43//+x9+++03+Pn5GVVbheeeew4eHh6YO3euFCJ37dqFc+fOITw8HC4uLvjzzz+xfPly/Pnnn/jtt9+gUCgAAH///Tf8/f1x5coVvPjii+jYsSMuXbqETZs2obi4GG3atEGPHj2wdu1aTJs2zWC5a9euhY2NDQYPHlxtbQUFBfj8888xYsQIREREoLCwEF988QWCg4Nx6NAh+Pj4GPRft24dCgsL8dJLL0GhUGD+/Pl45plncO7cOVhYWAAAdu7ciaFDh8LT0xOxsbG4fPkywsPD0aJFi1ptv2vXrqFPnz44c+YMJk+ejNatW2Pjxo0YM2YMrly5gilTpkjbdMSIEejfvz/ef/99AEBqair2798v9Zk1axZiY2Mxfvx4+Pv7o6CgAEeOHMHRo0fx2GOP1ao+ogZJEMnMqlWrBABx+PBhsXjxYmFjYyOKi4uFEEI899xzom/fvkIIIVq1aiUGDRokTbd161YBQLz77rsG83v22WeFQqEQZ86cEUIIkZycLACIiRMnGvQbOXKkACBiYmKktnHjxglXV1eRm5tr0Hf48OHCzs5OqistLU0AEKtWrbrtul2/fl3odDqDtrS0NKFSqcScOXOktpUrVwoAYuHChZXmodfrhRBC/PzzzwKAePXVV6vtc7u6bl3XmJgYAUCMGDGiUt+K9bzZN998IwCIX3/9VWoLDQ0VZmZm4vDhw9XW9NlnnwkAIjU1VRpXWloqHBwcRFhYWKXpblZeXi5KSkoM2v755x/h7Owsxo4dK7VVrHezZs1EXl6e1P79998LAOK///2v1Obj4yNcXV3FlStXpLadO3cKAKJVq1a3rUcIIXr37i169+4tvY6LixMAxJo1awzWLzAwUFhbW4uCggIhhBBTpkwRtra2ory8vNp5e3t7G7zHieSKh8lI1p5//nlcu3YNP/zwAwoLC/HDDz9Ue4hsx44dMDc3x6uvvmrQ/tprr0EIgR9//FHqB6BSv1v38ggh8N133yEkJARCCOTm5kpDcHAw8vPzcfToUaPWR6VSwczsxq+1TqfD5cuXYW1tjQ4dOhjM67vvvoODgwNeeeWVSvOo2Avz3XffQaFQICYmpto+tfHyyy9XarO0tJT+f/36deTm5uKRRx4BAKluvV6PrVu3IiQkpMq9UhU1Pf/881Cr1Vi7dq007qeffkJubi5eeOGF29Zmbm4OpVIpLS8vLw/l5eXw8/Or8mcxbNgwNGnSRHrds2dPADf20AFAZmYmkpOTERYWBjs7O6nfY489Bk9Pz9vWUp0dO3bAxcUFI0aMkNosLCzw6quv4urVq/jll18AAPb29igqKrrtIS97e3v8+eefOH36dK1qIXpQMAyRrDk6OiIoKAjr1q3D5s2bodPp8Oyzz1bZ98KFC2jevDlsbGwM2jt16iSNr/jXzMxMOtRUoUOHDgavc3JycOXKFSxfvhyOjo4GQ3h4OIAb54YYQ6/X46OPPoKHhwdUKhUcHBzg6OiIY8eOIT8/X+p39uxZdOjQAY0aVX+k/OzZs2jevDmaNm1qVA130rp160pteXl5mDJlCpydnWFpaQlHR0epX0XdOTk5KCgoQJcuXW47f3t7e4SEhBhcKbh27Vq4ubmhX79+d6zvyy+/RNeuXaVzaBwdHbF9+3aD7VehZcuWBq8rgtE///wD4N/3hIeHR6Vpb30/1NSFCxfg4eEhhd4Kt74PJ06ciPbt22PAgAFo0aIFxo4di/j4eINp5syZgytXrqB9+/bw8vLCG2+8gWPHjtWqLqKGjOcMkeyNHDkSERER0Gq1GDBgAOzt7e/LcvV6PQDghRdeQFhYWJV9unbtatQ8586di5kzZ2Ls2LF455130LRpU5iZmWHq1KnS8upSdXuIdDpdtdPcvBeowvPPP48DBw7gjTfegI+PD6ytraHX6/HEE0/Uqu7Q0FBs3LgRBw4cgJeXF7Zt24aJEydWChC3WrNmDcaMGYMhQ4bgjTfegJOTE8zNzREbG2twYnkFc3PzKucjbjmh3hScnJyQnJyMn376CT/++CN+/PFHrFq1CqGhodLJ1r169cLZs2fx/fffY+fOnfj888/x0UcfYdmyZRg/fryJ14Do/mEYItl7+umn8dJLL+G3337Dhg0bqu3XqlUr7N69G4WFhQZ7h06ePCmNr/hXr9dLe18qnDp1ymB+FVea6XQ6BAUF1cm6bNq0CX379sUXX3xh0H7lyhU4ODhIr9u2bYuDBw+irKxMOtH3Vm3btsVPP/2EvLy8avcOVewJuXLlikF7xd6Jmvjnn3+QkJCA2bNnIzo6Wmq/9dCNo6MjbG1tceLEiTvO84knnoCjoyPWrl2LgIAAFBcXY/To0XecbtOmTWjTpg02b95sEPSqOlRYExXviaoOQ936fjBmnseOHYNerzcId7e+DwFAqVQiJCQEISEh0Ov1mDhxIj777DPMnDkT7dq1AwA0bdoU4eHhCA8Px9WrV9GrVy/MmjWLYYhkhYfJSPasra2xdOlSzJo1CyEhIdX2GzhwIHQ6HRYvXmzQ/tFHH0GhUEhXpFX8e+vVaHFxcQavzc3NMXToUHz33XdVfsHn5OQYvS7m5uaV9kps3LgRly5dMmgbOnQocnNzK60L8O9ejaFDh0IIgdmzZ1fbx9bWFg4ODvj1118Nxn/66adG1XzzPCvcur3MzMwwZMgQ/Pe//5Uu7a+qJgBo1KgRRowYgW+//RarV6+Gl5dXjfayVVXLwYMHkZiYWOP1uZmrqyt8fHzw5ZdfGhxm27VrF1JSUmo1z4EDB0Kr1RoE9/LycnzyySewtrZG7969AaDSbQnMzMykbVBSUlJlH2tra7Rr104aTyQX3DNEBFR7mOpmISEh6Nu3L9566y2cP38e3t7e2LlzJ77//ntMnTpVOkfIx8cHI0aMwKeffor8/Hx0794dCQkJOHPmTKV5zps3D3v27EFAQAAiIiLg6emJvLw8HD16FLt370ZeXp5R6/Hkk09izpw5CA8PR/fu3XH8+HGsXbsWbdq0MegXGhqKr776CpGRkTh06BB69uyJoqIi7N69GxMnTsTgwYPRt29fjB49Gh9//DFOnz4tHbL63//+h759+2Ly5MkAbtxGYN68eRg/fjz8/Pzw66+/4q+//qpxzba2tujVqxfmz5+PsrIyuLm5YefOnUhLS6vUd+7cudi5cyd69+6NF198EZ06dUJmZiY2btyIffv2GRziDA0Nxccff4w9e/ZIl5bXZPtt3rwZTz/9NAYNGoS0tDQsW7YMnp6euHr1ao3X6WaxsbEYNGgQHn30UYwdOxZ5eXn45JNP0Llz51rN88UXX8Rnn32GMWPGICkpCe7u7ti0aRP279+PuLg4aa/l+PHjkZeXh379+qFFixa4cOECPvnkE/j4+EjnF3l6eqJPnz7w9fVF06ZNceTIEWzatEn62RLJhomuYiMymZsvrb+dWy+tF0KIwsJCMW3aNNG8eXNhYWEhPDw8xIIFC6TLuitcu3ZNvPrqq6JZs2aicePGIiQkRFy8eLHS5eZCCJGVlSUmTZokNBqNsLCwEC4uLqJ///5i+fLlUh9jLq1/7bXXhKurq7C0tBQ9evQQiYmJlS7PFuLG5exvvfWWaN26tbTcZ599Vpw9e1bqU15eLhYsWCA6duwolEqlcHR0FAMGDBBJSUkG8xk3bpyws7MTNjY24vnnnxfZ2dnVXlqfk5NTqe6MjAzx9NNPC3t7e2FnZyeee+458ffff1e5vS5cuCBCQ0OFo6OjUKlUok2bNmLSpEmVLokXQojOnTsLMzMzkZGRcdvtVkGv14u5c+eKVq1aCZVKJbp16yZ++OEHERYWZnAZfMXPY8GCBZXmUVXN3333nejUqZNQqVTC09NTbN68udI8q1PVzy4rK0uEh4cLBwcHoVQqhZeXV6X3xqZNm8Tjjz8unJychFKpFC1bthQvvfSSyMzMlPq8++67wt/fX9jb2wtLS0vRsWNH8d5774nS0tI71kX0IFEIUQ/O9CMiuge6deuGpk2bIiEhwdSlEFE9xnOGiOiBdOTIESQnJyM0NNTUpRBRPcc9Q0T0QDlx4gSSkpLw4YcfIjc3F+fOnYNarTZ1WURUj3HPEBE9UDZt2oTw8HCUlZXhm2++YRAiojsyOgz9+uuvCAkJQfPmzaFQKLB169Y7TrN371489NBDUKlUaNeuXZVPuCYiqguzZs2CXq9HamqqdJk5ETUMpsoYRoehoqIieHt7Y8mSJTXqn5aWhkGDBqFv375ITk7G1KlTMX78ePz0009GF0tEREQPLlNljLs6Z0ihUGDLli0YMmRItX2mT5+O7du3G9xUbvjw4bhy5Uql5+QQERERAfc3Y9zzmy4mJiZWetRAcHBwpSd436ykpMTgDqjl5eVITU2FRqO547OFiIiIqH7Q6/VIT0+Hp6enwYOhVSoVVCrVXc+/NhmjKvc8DGm1Wjg7Oxu0OTs7o6CgANeuXavyoY2xsbFVPgKAiIiIGr6YmBjMmjXrrudTm4xRlXr5OI6oqChERkZKry9evIguXbrg0KFDcHV1NWFlREREVFOZmZnw9/fHiRMnoNFopPa62CtUl+55GHJxcUFWVpZBW1ZWFmxtbatNbLfuPrOzswNw46GHLVq0uHfFEhERUZ2zs7ODra1tnc+3NhmjKvf8BJzAwMBKt8LftWsXAgMD7/WiiYiI6AFWVxnD6DB09epVJCcnIzk5GcCNy9qSk5ORnp4O4MYhrptvf//yyy/j3LlzePPNN3Hy5El8+umn+PbbbzFt2jRjF01EREQPMJNlDGOf7Lpnzx4BoNIQFhYmhBAiLCys0hOW9+zZI3x8fIRSqRRt2rS545O3b1XxtO+LFy8aWy4RERGZiLHf36bIGEI0kKfWZ2RkQKPR4OLFizxniIiIqIFoKN/fvGkPERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJWq3C0JIlS+Du7g61Wo2AgAAcOnSo2r5lZWWYM2cO2rZtC7VaDW9vb8THx9e6YCIiIqK6ZHQY2rBhAyIjIxETE4OjR4/C29sbwcHByM7OrrL/22+/jc8++wyffPIJUlJS8PLLL+Ppp5/G77//ftfFExEREd0thRBCGDNBQEAAHn74YSxevBgAoNfrodFo8Morr2DGjBmV+jdv3hxvvfUWJk2aJLUNHToUlpaWWLNmTY2WmZGRAY1Gg4sXL6JFixbGlEtEREQm0lC+v43aM1RaWoqkpCQEBQX9OwMzMwQFBSExMbHKaUpKSqBWqw3aLC0tsW/fvmqXU1JSgoKCAmkoLCw0pkwiIiKiGjMqDOXm5kKn08HZ2dmg3dnZGVqttsppgoODsXDhQpw+fRp6vR67du3C5s2bkZmZWe1yYmNjYWdnJw2enp7GlElERERUY/f8arJFixbBw8MDHTt2hFKpxOTJkxEeHg4zs+oXHRUVhfz8fGlISUm512USERGRTBkVhhwcHGBubo6srCyD9qysLLi4uFQ5jaOjI7Zu3YqioiJcuHABJ0+ehLW1Ndq0aVPtclQqFWxtbaXBxsbGmDKJiIiIasyoMKRUKuHr64uEhASpTa/XIyEhAYGBgbedVq1Ww83NDeXl5fjuu+8wePDg2lVMREREVIcaGTtBZGQkwsLC4OfnB39/f8TFxaGoqAjh4eEAgNDQULi5uSE2NhYAcPDgQVy6dAk+Pj64dOkSZs2aBb1ejzfffLNu14SIiIioFowOQ8OGDUNOTg6io6Oh1Wrh4+OD+Ph46aTq9PR0g/OBrl+/jrfffhvnzp2DtbU1Bg4ciK+//hr29vZ1thJEREREtWX0fYZMoaHcp4CIiIj+1VC+v/lsMiIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKqN5YsWQJ3d3eo1WoEBATg0KFDt+0fFxeHDh06wNLSEhqNBtOmTcP169eNWibDEBEREdULGzZsQGRkJGJiYnD06FF4e3sjODgY2dnZVfZft24dZsyYgZiYGKSmpuKLL77Ahg0b8J///Meo5TIMERERUb2wcOFCREREIDw8HJ6enli2bBmsrKywcuXKKvsfOHAAPXr0wMiRI+Hu7o7HH38cI0aMuOPepFsxDBEREdE9VVhYiIKCAmkoKSmp1Ke0tBRJSUkICgqS2szMzBAUFITExMQq59u9e3ckJSVJ4efcuXPYsWMHBg4caFR9DENERER0T3l6esLOzk4aYmNjK/XJzc2FTqeDs7OzQbuzszO0Wm2V8x05ciTmzJmDRx99FBYWFmjbti369Olj9GGyRkb1JiIiIjJSSkoK3NzcpNcqlapO5rt3717MnTsXn376KQICAnDmzBlMmTIF77zzDmbOnFnj+TAMERER0T1lY2MDW1vb2/ZxcHCAubk5srKyDNqzsrLg4uJS5TQzZ87E6NGjMX78eACAl5cXioqK8OKLL+Ktt96CmVnNDoDxMBkRERGZnFKphK+vLxISEqQ2vV6PhIQEBAYGVjlNcXFxpcBjbm4OABBC1HjZtQpDprgHABERET3YIiMjsWLFCnz55ZdITU3FhAkTUFRUhPDwcABAaGgooqKipP4hISFYunQp1q9fj7S0NOzatQszZ85ESEiIFIpqwujDZBX3AFi2bBkCAgIQFxeH4OBgnDp1Ck5OTpX6V9wDYOXKlejevTv++usvjBkzBgqFAgsXLjR28URERPSAGjZsGHJychAdHQ2tVgsfHx/Ex8dLJ1Wnp6cb7Al6++23oVAo8Pbbb+PSpUtwdHRESEgI3nvvPaOWqxDG7EcCEBAQgIcffhiLFy8GcGMXlkajwSuvvIIZM2ZU6j958mSkpqYa7PZ67bXXcPDgQezbt69Gy8zIyIBGo8HFixfRokULY8olIiIiE2ko399GHSa7X/cAKCkpMbgfQWFhoTFlEhEREdWYUYfJbncPgJMnT1Y5zciRI5Gbm4tHH30UQgiUl5fj5Zdfvu09AGJjYzF79mxjSiMiIiKqlXt+NdnN9wA4evQoNm/ejO3bt+Odd96pdpqoqCjk5+dLQ0pKyr0uk4iIiGTKqD1D9+seACqVyuCGTAUFBcaUSURERFRjRu0ZMuU9AIiIiIjuBaMvrY+MjERYWBj8/Pzg7++PuLi4SvcAcHNzk547EhISgoULF6Jbt27SrbJrcw8AIiIionvB6DBkqnsAEBEREd0LRt9nyBQayn0KiIiI6F8N5fubzyYjIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZq1UYWrJkCdzd3aFWqxEQEIBDhw5V27dPnz5QKBSVhkGDBtW6aCIiIqK6YnQY2rBhAyIjIxETE4OjR4/C29sbwcHByM7OrrL/5s2bkZmZKQ0nTpyAubk5nnvuubsunoiIiOhuGR2GFi5ciIiICISHh8PT0xPLli2DlZUVVq5cWWX/pk2bwsXFRRp27doFKysrhiEiIiKqF4wKQ6WlpUhKSkJQUNC/MzAzQ1BQEBITE2s0jy+++ALDhw9H48aNq+1TUlKCgoICaSgsLDSmTCIiIqIaMyoM5ebmQqfTwdnZ2aDd2dkZWq32jtMfOnQIJ06cwPjx42/bLzY2FnZ2dtLg6elpTJlERERENXZfryb74osv4OXlBX9//9v2i4qKQn5+vjSkpKTcpwqJiIhIbhoZ09nBwQHm5ubIysoyaM/KyoKLi8ttpy0qKsL69esxZ86cOy5HpVJBpVJJrwsKCowpk4iIiKjGjNozpFQq4evri4SEBKlNr9cjISEBgYGBt51248aNKCkpwQsvvFC7SomIiIjuAaP2DAFAZGQkwsLC4OfnB39/f8TFxaGoqAjh4eEAgNDQULi5uSE2NtZgui+++AJDhgxBs2bN6qZyIiIiojpgdBgaNmwYcnJyEB0dDa1WCx8fH8THx0snVaenp8PMzHCH06lTp7Bv3z7s3LmzbqomIiIiqiMKIYQwdRF3kpGRAY1Gg4sXL6JFixZ1Mk8hBIrLiutkXkRERA2dlYUVFApFnc7zXnx/3wtG7xl6UBSXFcM61trUZRAREdULV6OuorGy+nsAPsj4oFYiIiKSNdnuGbKysMLVqKumLoOIiKhesLKwMnUJJiPbMKRQKGS7O5CIiIj+xcNkREREJGuy3TMEIYBiXk1GREQEALCyAur4arKGQr5hqLgYsObVZERERACAq1eBxvI8fYSHyYiIiEjW5LtnyMrqRgomIiKiG9+LMiXfMKRQyHZ3IBEREf2Lh8mIiIhI1hiGiIiISNYYhoiIiEjWGIaIiIhI1hiGiIiIqN5YsmQJ3N3doVarERAQgEOHDt22/5UrVzBp0iS4urpCpVKhffv22LFjh1HLlO/VZERERFSvbNiwAZGRkVi2bBkCAgIQFxeH4OBgnDp1Ck5OTpX6l5aW4rHHHoOTkxM2bdoENzc3XLhwAfb29kYtl2GIiIiI6oWFCxciIiIC4eHhAIBly5Zh+/btWLlyJWbMmFGp/8qVK5GXl4cDBw7AwsICAODu7m70cnmYjIiIiO6pwsJCFBQUSENJSUmlPqWlpUhKSkJQUJDUZmZmhqCgICQmJlY5323btiEwMBCTJk2Cs7MzunTpgrlz50Kn0xlVH8MQERER3VOenp6ws7OThtjY2Ep9cnNzodPp4OzsbNDu7OwMrVZb5XzPnTuHTZs2QafTYceOHZg5cyY+/PBDvPvuu0bVx8NkREREdE+lpKTAzc1Neq1Sqepkvnq9Hk5OTli+fDnMzc3h6+uLS5cuYcGCBYiJianxfBiGiIiI6J6ysbGBra3tbfs4ODjA3NwcWVlZBu1ZWVlwcXGpchpXV1dYWFjA3NxcauvUqRO0Wi1KS0uhVCprVB8PkxEREZHJKZVK+Pr6IiEhQWrT6/VISEhAYGBgldP06NEDZ86cgV6vl9r++usvuLq61jgIAQxDREREVE9ERkZixYoV+PLLL5GamooJEyagqKhIurosNDQUUVFRUv8JEyYgLy8PU6ZMwV9//YXt27dj7ty5mDRpklHL5WEyIiIiqheGDRuGnJwcREdHQ6vVwsfHB/Hx8dJJ1enp6TAz+3c/jkajwU8//YRp06aha9eucHNzw5QpUzB9+nSjlqsQQog6XZN7ICMjAxqNBhcvXkSLFi1MXQ4RERHVQEP5/uZhMiIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKStVpdWr9kyRIsWLAAWq0W3t7e+OSTT+Dv719t/ytXruCtt97C5s2bkZeXh1atWiEuLg4DBw6sdeG30uv1KC0trbP50YNJqVQaXJZJRA2HTqdDWVmZqcugm9x69+eGyugwtGHDBkRGRmLZsmUICAhAXFwcgoODcerUKTg5OVXqX1paisceewxOTk7YtGkT3NzccOHCBdjb29dF/dIy0tLSDO5ASVQVMzMztG7d2qg7kxKRaQkhoNVqceXKFVOXQlWwt7eHi4sLFAqFqUupNaPD0MKFCxERESHdDXLZsmXYvn07Vq5ciRkzZlTqv3LlSuTl5eHAgQOwsLAAALi7u99d1TcRQiAzMxPm5ubQaDT8q5+qpdfr8ffffyMzMxMtW7Zs0L+4RHJSEYScnJxgZWXF3916QgiB4uJiZGdnA7jxnLCGyqgwVFpaiqSkJINbYZuZmSEoKAiJiYlVTrNt2zYEBgZi0qRJ+P777+Ho6IiRI0di+vTp1e5aKykpQUlJifS6sLCw2prKy8tRXFyM5s2bw8rKypjVIRlydHTE33//jfLycimcE1H9pdPppCDUrFkzU5dDt7C0tAQAZGdnw8nJqcEeMjNqN0pubi50Op10W+wKzs7O0Gq1VU5z7tw5bNq0CTqdDjt27MDMmTPx4Ycf4t133612ObGxsbCzs5MGT0/PavvqdDoA4GEPqpGK90nF+4aI6reKc4T4x279VfGzacjnc93zY0p6vR5OTk5Yvnw5fH19MWzYMLz11ltYtmxZtdNERUUhPz9fGlJSUu64HO42pZrg+4SoYeLvbv31IPxsjDpM5uDgAHNzc2RlZRm0Z2VlwcXFpcppXF1dK51t3qlTJ2i1WpSWlla5R0elUkGlUkmvCwoKjCmTiIiIqMaM2jOkVCrh6+uLhIQEqU2v1yMhIQGBgYFVTtOjRw+cOXPG4Eqvv/76C66urjy0RURERCZn9GGyyMhIrFixAl9++SVSU1MxYcIEFBUVSVeXhYaGGpxgPWHCBOTl5WHKlCn466+/sH37dsydOxeTJk2qu7UgIiKqZ/r06YOpU6eaugyqAaMvrR82bBhycnIQHR0NrVYLHx8fxMfHSydVp6enG1zertFo8NNPP2HatGno2rUr3NzcMGXKFEyfPr3u1oKIiIiolmp1B+rJkydj8uTJVY7bu3dvpbbAwED89ttvtVkU3UdlZWW83JyIiGTnwbtDoRBAUZFpBiGMKjU+Ph6PPvoo7O3t0axZMzz55JM4e/asND4jIwMjRoxA06ZN0bhxY/j5+eHgwYPS+P/+9794+OGHoVar4eDggKeffloap1AosHXrVoPl2dvbY/Xq1QCA8+fPQ6FQYMOGDejduzfUajXWrl2Ly5cvY8SIEXBzc4OVlRW8vLzwzTffGMxHr9dj/vz5aNeuHVQqFVq2bIn33nsPANCvX79KQTknJwdKpdLgXDMiortW1WdvaemNtpvuVWfQ9+YnFZSV3Wi7fr1mfe/CP//8g9DQUDRp0gRWVlYYMGAATp8+LY2/cOECQkJC0KRJEzRu3BidO3fGjh07pGlHjRoFR0dHWFpawsPDA6tWrbqresjQgxeGiosBa2vTDMXFRpVaVFSEyMhIHDlyBAkJCTAzM8PTTz8NvV6Pq1evonfv3rh06RK2bduGP/74A2+++aZ0Ivr27dvx9NNPY+DAgfj999+RkJBw2+fDVWfGjBmYMmUKUlNTERwcjOvXr8PX1xfbt2/HiRMn8OKLL2L06NE4dOiQNE1UVBTmzZuHmTNnIiUlBevWrZMOk44fPx7r1q0zuGnmmjVr4Obmhn79+hldHxFRtSo+e3Nz/21bsOBG261HL5ycbrSnp//btmTJjbZx4wz7urvfaE9N/bft//+QrK0xY8bgyJEj2LZtGxITEyGEwMCBA6V780yaNAklJSX49ddfcfz4cbz//vuwtrYGAOmz9scff0RqaiqWLl0KBweHu6qHDNXqMBnVjaFDhxq8XrlyJRwdHZGSkoIDBw4gJycHhw8fRtOmTQEA7dq1k/q+9957GD58OGbPni21eXt7G13D1KlT8cwzzxi0vf7669L/X3nlFfz000/49ttv4e/vj8LCQixatAiLFy9GWFgYAKBt27Z49NFHAQDPPPMMJk+ejO+//x7PP/88AGD16tUYM2bMA3EvCiIiY50+fRrbtm3D/v370b17dwDA2rVrodFosHXrVjz33HNIT0/H0KFD4eXlBQBo06aNNH16ejq6desGPz8/AHX7SCu64cELQ1ZWwNWrplu2EU6fPo3o6GgcPHgQubm50l6f9PR0JCcno1u3blIQulVycjIiIiLuuuSKX64KOp0Oc+fOxbfffotLly6htLQUJSUl0h1GU1NTUVJSgv79+1c5P7VajdGjR2PlypV4/vnncfToUZw4cQLbtm2761qJiAxUfNbf/Nn7xhvA1KlAo1u+3v7/+Vn4/8dHAAAmTQIiIoBbHyFx/nzlvmPG1LrM1NRUNGrUCAEBAVJbs2bN0KFDB6T+/96nV199FRMmTMDOnTsRFBSEoUOHomvXrgBuXJU9dOhQHD16FI8//jiGDBkihSqqGw/eYTKFAmjc2DSDkXs+QkJCkJeXhxUrVuDgwYPS+UClpaXS816qc6fxCoUC4pZzmKq6VXrjxo0NXi9YsACLFi3C9OnTsWfPHiQnJyM4OBilpaU1Wi5w41DZrl27kJGRgVWrVqFfv35o1arVHacjIjJKVZ+9SuWNtptu3GvQ9+aHeVtY3GhTq2vW9x4aP348zp07h9GjR+P48ePw8/PDJ598AgAYMGAALly4gGnTpuHvv/9G//79Dfbg09178MJQA3H58mWcOnUKb7/9Nvr3749OnTrhn3/+kcZ37doVycnJyMvLq3L6rl273vaEZEdHR2RmZkqvT58+jeIanNO0f/9+DB48GC+88AK8vb3Rpk0b/PXXX9J4Dw8PWFpa3nbZXl5e8PPzw4oVK7Bu3TqMHTv2jsslInpQderUCeXl5QYXwFR8B9z87E2NRoOXX34ZmzdvxmuvvYYVK1ZI4xwdHREWFoY1a9YgLi4Oy5cvv6/r8KB78A6TNRBNmjRBs2bNsHz5cri6uiI9PR0zZsyQxo8YMQJz587FkCFDEBsbC1dXV/z+++9o3rw5AgMDERMTg/79+6Nt27YYPnw4ysvLsWPHDun+Tf369cPixYsRGBgInU6H6dOn1+iyeQ8PD2zatAkHDhxAkyZNsHDhQmRlZUm/sGq1GtOnT8ebb74JpVKJHj16ICcnB3/++SfG3XQS4vjx4zF58mQ0btzY4Co3IiK58fDwwODBgxEREYHPPvsMNjY2mDFjBtzc3DB48GAAN87fHDBgANq3b49//vkHe/bsQadOnQAA0dHR8PX1RefOnVFSUoIffvhBGkd1g3uGTMTMzAzr169HUlISunTpgmnTpmHBggXSeKVSiZ07d8LJyQkDBw6El5cX5s2bJz3jrU+fPti4cSO2bdsGHx8f9OvXz+CKrw8//BAajQY9e/bEyJEj8frrr9foqc9vv/02HnroIQQHB6NPnz5wcXHBkCFDDPrMnDkTr732GqKjo9GpUycMGzYM2RXH4//fiBEj0KhRI4wYMQLqW3dBExHJzKpVq+Dr64snn3wSgYGBEEJgx44d0h+pOp0OkyZNQqdOnfDEE0+gffv2+PTTTwHc+D6IiopC165d0atXL5ibm2P9+vWmXJ0HjkLcemJJPZSRkQGNRoOLFy+iRYsWBuOuX7+OtLQ0tG7dml+69cj58+fRtm1bHD58GA899JCpy5Hw/ULUsPB3tv673c/odt/f9QkPk1GdKisrw+XLl/H222/jkUceqVdBiIiIqCo8TEZ1av/+/XB1dcXhw4exbNkyU5dDRER0R9wzRHWqT58+lS7pJyIiqs+4Z4iIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYagBc3d3R1xcnKnLICKie8CYz3iFQoGtW7fe03oeZAxDREREJGsMQ2QSOp0Oer3e1GUQERE9eGFICIGi0iKTDMbceXn58uVo3rx5pUAwePBgjB07FmfPnsXgwYPh7OwMa2trPPzww9i9e3ett8vChQvh5eWFxo0bQ6PRYOLEibh69apBn/3796NPnz6wsrJCkyZNEBwcjH/++QcAoNfrMX/+fLRr1w4qlQotW7bEe++9BwDYu3cvFAoFrly5Is0rOTkZCoUC58+fBwCsXr0a9vb22LZtGzw9PaFSqZCeno7Dhw/jscceg4ODA+zs7NC7d28cPXrUoK4rV67gpZdegrOzM9RqNbp06YIffvgBRUVFsLW1xaZNmwz6b926FY0bN0ZhYWGttxcR1X+3+zy+Xn69xn2vlV2rUV9j3O/P+FsdP34c/fr1g6WlJZo1a4YXX3zR4DN/79698Pf3R+PGjWFvb48ePXrgwoULAIA//vgDffv2hY2NDWxtbeHr64sjR47UWW310QP3OI7ismJYx1qbZNlXo66isbJxjfo+99xzeOWVV7Bnzx70798fAJCXl4f4+Hjs2LEDV69excCBA/Hee+9BpVLhq6++QkhICE6dOoWWLVsaXZuZmRk+/vhjtG7dGufOncPEiRPx5ptv4tNPPwVwI7z0798fY8eOxaJFi9CoUSPs2bMHOp0OABAVFYUVK1bgo48+wqOPPorMzEycPHnSqBqKi4vx/vvv4/PPP0ezZs3g5OSEc+fOISwsDJ988gmEEPjwww8xcOBAnD59GjY2NtDr9RgwYAAKCwuxZs0atG3bFikpKTA3N0fjxo0xfPhwrFq1Cs8++6y0nIrXNjY2Rm8nImo4bvdZP9BjILaP3C69dvrACcVlxVX27d2qN/aO2Su9dl/kjtzi3Er9REzN/+C935/xNysqKkJwcDACAwNx+PBhZGdnY/z48Zg8eTJWr16N8vJyDBkyBBEREfjmm29QWlqKQ4cOQaFQAABGjRqFbt26YenSpTA3N0dycjIsLCzuqqb67oELQw1FkyZNMGDAAKxbt076Rdm0aRMcHBzQt29fmJmZwdvbW+r/zjvvYMuWLdi2bRsmT55s9PKmTp0q/d/d3R3vvvsuXn75ZSkMzZ8/H35+ftJrAOjcuTMAoLCwEIsWLcLixYsRFhYGAGjbti0effRRo2ooKyvDp59+arBe/fr1M+izfPly2Nvb45dffsGTTz6J3bt349ChQ0hNTUX79u0BAG3atJH6jx8/Ht27d0dmZiZcXV2RnZ2NHTt21OlfWERExrrfn/E3W7duHa5fv46vvvoKjRvf+AN98eLFCAkJwfvvvw8LCwvk5+fjySefRNu2bQEAnTp1kqZPT0/HG2+8gY4dOwIAPDw87qqehuCBC0NWFla4GnX1zh3v0bKNMWrUKERERODTTz+FSqXC2rVrMXz4cJiZmeHq1auYNWsWtm/fjszMTJSXl+PatWtIT0+vVW27d+9GbGwsTp48iYKCApSXl+P69esoLi6GlZUVkpOT8dxzz1U5bWpqKkpKSqRf6NpSKpXo2rWrQVtWVhbefvtt7N27F9nZ2dDpdCguLpbWMzk5GS1atJCC0K38/f3RuXNnfPnll5gxYwbWrFmDVq1aoVevXndVKxHVf7f7rDc3Mzd4nf16drV9zRSGZ4ycn3L+ruqqcD8/42+WmpoKb29vKQgBQI8ePaDX63Hq1Cn06tULY8aMQXBwMB577DEEBQXh+eefh6urKwAgMjIS48ePx9dff42goCA899xzUmh6UD1w5wwpFAo0VjY2yVCxi7GmQkJCIITA9u3bcfHiRfzvf//DqFGjAACvv/46tmzZgrlz5+J///sfkpOT4eXlhdLSUqO3yfnz5/Hkk0+ia9eu+O6775CUlIQlS5YAgDQ/S0vLaqe/3TjgxiE4AAbnTJWVlVU5n1u3UVhYGJKTk7Fo0SIcOHAAycnJaNasWY3qqjB+/HisXr0awI1DZOHh4Ub/LIio4bnd57G6kbrGfS0tLGvU11j36zO+NlatWoXExER0794dGzZsQPv27fHbb78BAGbNmoU///wTgwYNws8//wxPT09s2bLlvtRlKg9cGGpI1Go1nnnmGaxduxbffPMNOnTogIceegjAjZOZx4wZg6effhpeXl5wcXGRTkY2VlJSEvR6PT788EM88sgjaN++Pf7++2+DPl27dkVCQkKV03t4eMDS0rLa8Y6OjgCAzMxMqS05OblGte3fvx+vvvoqBg4ciM6dO0OlUiE3999j9V27dkVGRgb++uuvaufxwgsv4MKFC/j444+RkpIiHcojIjKl+/UZf6tOnTrhjz/+QFHRvyd979+/H2ZmZujQoYPU1q1bN0RFReHAgQPo0qUL1q1bJ41r3749pk2bhp07d+KZZ57BqlWr6qS2+ophyMRGjRqF7du3Y+XKldJfDMCNALJ582YkJyfjjz/+wMiRI2t9KXq7du1QVlaGTz75BOfOncPXX3+NZcuWGfSJiorC4cOHMXHiRBw7dgwnT57E0qVLkZubC7VajenTp+PNN9/EV199hbNnz+K3337DF198Ic1fo9Fg1qxZOH36NLZv344PP/ywRrV5eHjg66+/RmpqKg4ePIhRo0YZ7A3q3bs3evXqhaFDh2LXrl1IS0vDjz/+iPj4eKlPkyZN8Mwzz+CNN97A448/jhYtWtRqOxER1bX78Rlf1TLVajXCwsJw4sQJ7NmzB6+88gpGjx4NZ2dnpKWlISoqComJibhw4QJ27tyJ06dPo1OnTrh27RomT56MvXv34sKFC9i/fz8OHz5scE7RA0k0ABcvXhQAxMWLFyuNu3btmkhJSRHXrl0zQWV3T6fTCVdXVwFAnD17VmpPS0sTffv2FZaWlkKj0YjFixeL3r17iylTpkh9WrVqJT766KMaLWfhwoXC1dVVWFpaiuDgYPHVV18JAOKff/6R+uzdu1d0795dqFQqYW9vL4KDg6XxOp1OvPvuu6JVq1bCwsJCtGzZUsydO1eadt++fcLLy0uo1WrRs2dPsXHjRgFApKWlCSGEWLVqlbCzs6tU19GjR4Wfn59Qq9XCw8NDbNy4sdJ6Xb58WYSHh4tmzZoJtVotunTpIn744QeD+SQkJAgA4ttvv73tdmjo7xciuWnov7P36zMegNiyZYv0+tixY6Jv375CrVaLpk2bioiICFFYWCiEEEKr1YohQ4YIV1dXoVQqRatWrUR0dLTQ6XSipKREDB8+XGg0GqFUKkXz5s3F5MmTb7v9b/czut33d32iEMKIm+OYSEZGBjQaDS5evFjpr/7r168jLS0NrVu3hlqtrmYO9KD7+uuvMW3aNPz9999QKpXV9uP7hahh4e9s/Xe7n9Htvr/rk1odJluyZAnc3d2hVqsREBCAQ4cOVdt39erVUCgUBgPf0FRXiouLcfbsWcybNw8vvfTSbYMQERFRVYwOQxs2bEBkZCRiYmJw9OhReHt7Izg4GNnZ1V+2aGtri8zMTGmouMsl1Y21a9fC2tq6yqHiXkEPqvnz56Njx45wcXFBVFSUqcshIqpzcv6Mv1+Mvs/QwoULERERgfDwcADAsmXLpJPDZsyYUeU0CoUCLi4ud1cpVeupp55CQEBAleMe9LuGzpo1C7NmzTJ1GURE94ycP+PvF6PCUGlpKZKSkgz+AjczM0NQUBASExOrne7q1ato1aoV9Ho9HnroIcydO/e2abakpAQlJSXSaz5j6vZsbGz46AkiogcUP+PvPaMOk+Xm5kKn08HZ2dmg3dnZGVqttsppOnTogJUrV+L777/HmjVroNfr0b17d2RkZFS7nNjYWNjZ2UmDp6fnHWtrAOeBUz3A9wlRw8Tf3frrQfjZ3PP7DAUGBiI0NBQ+Pj7o3bs3Nm/eDEdHR3z22WfVThMVFYX8/HxpSElJqbavufmNW67fr7t2UsNW8T6peN8QUf1WcRiouLjqh6yS6VX8bBryITujDpM5ODjA3NwcWVlZBu1ZWVk1PifIwsIC3bp1w5kzZ6rto1KpoFKppNcFBQXV9m3UqBGsrKyQk5MDCwsL6dEQRLfS6/XIycmBlZUVGjV64B7LR/RAMjc3h729vXSRjpWVFR+3U08IIVBcXIzs7GzY29s36D8yjfpGUCqV8PX1RUJCAoYMGQLgxhdMQkJCjZ+yq9PpcPz4cQwcONDoYquiUCjg6uqKtLQ0XqVGd2RmZoaWLVvyw5SoAan4Y/t2Vy2T6djb2zf4i6SM/vM4MjISYWFh8PPzg7+/P+Li4lBUVCRdXRYaGgo3NzfExsYCAObMmYNHHnkE7dq1w5UrV7BgwQJcuHAB48ePr7OVUCqV8PDw4KEyuiOlUsm9h0QNTMUfvU5OTlU+BJpMx8LCokHvEapgdBgaNmwYcnJyEB0dDa1WCx8fH8THx0snVaenpxt82fzzzz+IiIiAVqtFkyZN4OvriwMHDtTopGhjmJmZ8WaOREQPMHNz8wfii5fqnwb/OA4iIiKqnxrK9zePFxAREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREVG9sWTJEri7u0OtViMgIACHDh2q0XTr16+HQqGQnpBhDIYhIiIiqhc2bNiAyMhIxMTE4OjRo/D29kZwcPAdH8Vy/vx5vP766+jZs2etlsswRERERPdUYWEhCgoKpKGkpKTKfgsXLkRERATCw8Ph6emJZcuWwcrKCitXrqx23jqdDqNGjcLs2bPRpk2bWtXHMERERET3lKenJ+zs7KSh4vmlNystLUVSUhKCgoKkNjMzMwQFBSExMbHaec+ZMwdOTk4YN25cresz+tlkRERERMZISUmBm5ub9FqlUlXqk5ubC51OJz3rtIKzszNOnjxZ5Xz37duHL774AsnJyXdVH8MQERER3VM2NjawtbWt03kWFhZi9OjRWLFiBRwcHO5qXgxDREREZHIODg4wNzdHVlaWQXtWVhZcXFwq9T979izOnz+PkJAQqU2v1wMAGjVqhFOnTqFt27Y1WjbPGSIiIiKTUyqV8PX1RUJCgtSm1+uRkJCAwMDASv07duyI48ePIzk5WRqeeuop9O3bF8nJydBoNDVeNvcMERERUb0QGRmJsLAw+Pn5wd/fH3FxcSgqKkJ4eDgAIDQ0FG5uboiNjYVarUaXLl0Mpre3tweASu13wjBERERE9cKwYcOQk5OD6OhoaLVa+Pj4ID4+XjqpOj09HWZmdX9QSyGEEHU+1zqWkZEBjUaDixcvokWLFqYuh4iIiGqgoXx/85whIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikjWGISIiIpI1hiEiIiKSNYYhIiIikrVahaElS5bA3d0darUaAQEBOHToUI2mW79+PRQKBYYMGVKbxRIRERHVOaPD0IYNGxAZGYmYmBgcPXoU3t7eCA4ORnZ29m2nO3/+PF5//XX07Nmz1sUSERER1TWjw9DChQsRERGB8PBweHp6YtmyZbCyssLKlSurnUan02HUqFGYPXs22rRpc1cFExEREdUlo8JQaWkpkpKSEBQU9O8MzMwQFBSExMTEaqebM2cOnJycMG7cuBotp6SkBAUFBdJQWFhoTJlERERENWZUGMrNzYVOp4Ozs7NBu7OzM7RabZXT7Nu3D1988QVWrFhR4+XExsbCzs5OGjw9PY0pk4iIiKjG7unVZIWFhRg9ejRWrFgBBweHGk8XFRWF/Px8aUhJSbmHVRIREZGcNTKms4ODA8zNzZGVlWXQnpWVBRcXl0r9z549i/PnzyMkJERq0+v1NxbcqBFOnTqFtm3bVppOpVJBpVJJrwsKCowpk4iIiKjGjNozpFQq4evri4SEBKlNr9cjISEBgYGBlfp37NgRx48fR3JysjQ89dRT6Nu3L5KTk6HRaO5+DYiIiIjuglF7hgAgMjISYWFh8PPzg7+/P+Li4lBUVITw8HAAQGhoKNzc3BAbGwu1Wo0uXboYTG9vbw8AldqJiIiITMHoMDRs2DDk5OQgOjoaWq0WPj4+iI+Pl06qTk9Ph5kZb2xNREREDYNCCCFMXcSdZGRkQKPR4OLFi2jRooWpyyEiIqIaaCjf39yFQ0RERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREssYwRERERLLGMERERESyxjBEREREslarMLRkyRK4u7tDrVYjICAAhw4dqrbv5s2b4efnB3t7ezRu3Bg+Pj74+uuva10wERERUV0yOgxt2LABkZGRiImJwdGjR+Ht7Y3g4GBkZ2dX2b9p06Z46623kJiYiGPHjiE8PBzh4eH46aef7rp4IiIiorulEEIIYyYICAjAww8/jMWLFwMA9Ho9NBoNXnnlFcyYMaNG83jooYcwaNAgvPPOOzXqn5GRAY1Gg4sXL6JFixbGlEtEREQm0lC+v43aM1RaWoqkpCQEBQX9OwMzMwQFBSExMfGO0wshkJCQgFOnTqFXr17V9ispKUFBQYE0FBYWGlMmERERUY01MqZzbm4udDodnJ2dDdqdnZ1x8uTJaqfLz8+Hm5sbSkpKYG5ujk8//RSPPfZYtf1jY2Mxe/ZsY0ojIiIiqpX7cjWZjY0NkpOTcfjwYbz33nuIjIzE3r17q+0fFRWF/Px8aUhJSbkfZRIREZEMGbVnyMHBAebm5sjKyjJoz8rKgouLS7XTmZmZoV27dgAAHx8fpKamIjY2Fn369Kmyv0qlgkqlkl4XFBQYUyYRERFRjRm1Z0ipVMLX1xcJCQlSm16vR0JCAgIDA2s8H71ej5KSEmMWTURERHRPGLVnCAAiIyMRFhYGPz8/+Pv7Iy4uDkVFRQgPDwcAhIaGws3NDbGxsQBunP/j5+eHtm3boqSkBDt27MDXX3+NpUuX1u2aEBEREdWC0ecMDRs2DB988AGio6Ph4+OD5ORkxMfHSydVp6enIzMzU+pfVFSEiRMnonPnzujRowe+++47rFmzBuPHj6+7tSAiIqIHgjE3dl6xYgV69uyJJk2aoEmTJggKCrpt/+oYfZ8hU2go9ykgIiKifxn7/b1hwwaEhoZi2bJlCAgIQFxcHDZu3IhTp07BycmpUv9Ro0ahR48e6N69O9RqNd5//31s2bIFf/75J9zc3GpcJ8MQERER3RMV398pKSkG4eTWC6Uq3O2NnXU6HZo0aYLFixcjNDS0xnXyQa1ERER0T3l6esLOzk4aKs4rvtnd3tgZAIqLi1FWVoamTZsaVZ/RJ1ATERERGaOqPUO3qu2NnW82ffp0NG/e3CBQ1QTDEBEREd1TNjY2sLW1vafLmDdvHtavX4+9e/dCrVYbNS3DEBEREZlcbW/sDAAffPAB5s2bh927d6Nr165GL5vnDBEREZHJ1fbGzvPnz8c777yD+Ph4+Pn51WrZ3DNERERE9YKxN3Z+//33ER0djXXr1sHd3R1arRYAYG1tDWtr6xovl2GIiIiI6oVhw4YhJycH0dHR0Gq18PHxqXRjZzOzfw9qLV26FKWlpXj22WcN5hMTE4NZs2bVeLm8zxARERHdEw3l+5vnDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkawxDBEREZGsMQwRERGRrDEMERERkazVKgwtWbIE7u7uUKvVCAgIwKFDh6rtu2LFCvTs2RNNmjRBkyZNEBQUdNv+RERERPeT0WFow4YNiIyMRExMDI4ePQpvb28EBwcjOzu7yv579+7FiBEjsGfPHiQmJkKj0eDxxx/HpUuX7rp4IiIiorulEEIIYyYICAjAww8/jMWLFwMA9Ho9NBoNXnnlFcyYMeOO0+t0OjRp0gSLFy9GaGhojZaZkZEBjUaDixcvokWLFsaUS0RERCbSUL6/jdozVFpaiqSkJAQFBf07AzMzBAUFITExsUbzKC4uRllZGZo2bVptn5KSEhQUFEhDYWGhMWUSERER1ZhRYSg3Nxc6nQ7Ozs4G7c7OztBqtTWax/Tp09G8eXODQHWr2NhY2NnZSYOnp6cxZRIRERHV2H29mmzevHlYv349tmzZArVaXW2/qKgo5OfnS0NKSsp9rJKIiIjkpJExnR0cHGBubo6srCyD9qysLLi4uNx22g8++ADz5s3D7t270bVr19v2ValUUKlU0uuCggJjyiQiIiKqMaP2DCmVSvj6+iIhIUFq0+v1SEhIQGBgYLXTzZ8/H++88w7i4+Ph5+dX+2qJiIiI6phRe4YAIDIyEmFhYfDz84O/vz/i4uJQVFSE8PBwAEBoaCjc3NwQGxsLAHj//fcRHR2NdevWwd3dXTq3yNraGtbW1nW4KkRERETGMzoMDRs2DDk5OYiOjoZWq4WPjw/i4+Olk6rT09NhZvbvDqelS5eitLQUzz77rMF8YmJiMGvWrLurnoiIiOguGX2fIVNoKPcpICIion81lO9vPpuMiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkjWGIiIiIZI1hiIiIiGSNYYiIiIhkrVZhaMmSJXB3d4darUZAQAAOHTpUbd8///wTQ4cOhbu7OxQKBeLi4mpbKxERET3gjMkYALBx40Z07NgRarUaXl5e2LFjh9HLNDoMbdiwAZGRkYiJicHRo0fh7e2N4OBgZGdnV9m/uLgYbdq0wbx58+Di4mJ0gURERCQPxmaMAwcOYMSIERg3bhx+//13DBkyBEOGDMGJEyeMWq5CCCGMmSAgIAAPP/wwFi9eDADQ6/XQaDR45ZVXMGPGjNtO6+7ujqlTp2Lq1KlGFZmRkQGNRoOLFy+iRYsWRk1LREREpmHs97exGWPYsGEoKirCDz/8ILU98sgj8PHxwbJly2pcZ6Ma9wRQWlqKpKQkREVFSW1mZmYICgpCYmKiMbO6rZKSEpSUlEiv8/PzAQCZmZl1tgwiIiK6tyq+t/Pz82Frayu1q1QqqFQqg761yRiJiYmIjIw0aAsODsbWrVuNqtOoMJSbmwudTgdnZ2eDdmdnZ5w8edKoBd9ObGwsZs+eXand39+/zpZBRERE90eXLl0MXsfExGDWrFkGbbXJGFqttsr+Wq3WqPqMCkP3S1RUlEHSKy8vR2pqKjQaDczM6u4CuMLCQnh6eiIlJQU2NjZ1Nt8HFbdXzXFb1Ry3lXG4vWqO28o492J76fV6pKenw9PTE40a/Rs5bt0rZGpGhSEHBweYm5sjKyvLoD0rK6tOT46uavdZjx496mz+FQoKCgAAbm5uBrvvqGrcXjXHbVVz3FbG4faqOW4r49yr7dWyZcsa9atNxnBxcamTTGLUbhalUglfX18kJCRIbXq9HgkJCQgMDDRqwUREREQVapMxAgMDDfoDwK5du4zOJEYfJouMjERYWBj8/Pzg7++PuLg4FBUVITw8HAAQGhoKNzc3xMbGArhxQlRKSor0/0uXLiE5ORnW1tZo166dsYsnIiKiB5SxGWPKlCno3bs3PvzwQwwaNAjr16/HkSNHsHz5cqOWa3QYGjZsGHJychAdHQ2tVgsfHx/Ex8dLJzClp6cbnNfz999/o1u3btLrDz74AB988AF69+6NvXv3Grv4OqVSqRATE1Pvjl3WV9xeNcdtVXPcVsbh9qo5bivj1IftZWzG6N69O9atW4e3334b//nPf+Dh4YGtW7dWOmH7Toy+zxARERHRg4TPJiMiIiJZYxgiIiIiWWMYIiIiIlljGCIiIiJZYxgiIiIiWZN1GFqyZAnc3d2hVqsREBCAQ4cOmbokk5s1axYUCoXB0LFjR2n89evXMWnSJDRr1gzW1tYYOnRopbt/Pqh+/fVXhISEoHnz5lAoFJUeBCiEQHR0NFxdXWFpaYmgoCCcPn3aoE9eXh5GjRoFW1tb2NvbY9y4cbh69ep9XIv7507ba8yYMZXea0888YRBH7lsr9jYWDz88MOwsbGBk5MThgwZglOnThn0qcnvXnp6OgYNGgQrKys4OTnhjTfeQHl5+f1clXuuJtuqT58+ld5bL7/8skEfOWwrAFi6dCm6du0KW1tb2NraIjAwED/++KM0nu+rG2QbhjZs2IDIyEjExMTg6NGj8Pb2RnBwMLKzs01dmsl17twZmZmZ0rBv3z5p3LRp0/Df//4XGzduxC+//IK///4bzzzzjAmrvX+Kiorg7e2NJUuWVDl+/vz5+Pjjj7Fs2TIcPHgQjRs3RnBwMK5fvy71GTVqFP7880/s2rULP/zwA3799Ve8+OKL92sV7qs7bS8AeOKJJwzea998843BeLlsr19++QWTJk3Cb7/9hl27dqGsrAyPP/44ioqKpD53+t3T6XQYNGgQSktLceDAAXz55ZdYvXo1oqOjTbFK90xNthUAREREGLy35s+fL42Ty7YCgBYtWmDevHlISkrCkSNH0K9fPwwePBh//vknAL6vJEKm/P39xaRJk6TXOp1ONG/eXMTGxpqwKtOLiYkR3t7eVY67cuWKsLCwEBs3bpTaUlNTBQCRmJh4nyqsHwCILVu2SK/1er1wcXERCxYskNquXLkiVCqV+Oabb4QQQqSkpAgA4vDhw1KfH3/8USgUCnHp0qX7Vrsp3Lq9hBAiLCxMDB48uNpp5Ly9srOzBQDxyy+/CCFq9ru3Y8cOYWZmJrRardRn6dKlwtbWVpSUlNzfFbiPbt1WQgjRu3dvMWXKlGqnkeu2qtCkSRPx+eef8311E1nuGSotLUVSUhKCgoKkNjMzMwQFBSExMdGEldUPp0+fRvPmzdGmTRuMGjUK6enpAICkpCSUlZUZbLeOHTuiZcuWst9uaWlp0Gq1BtvGzs4OAQEB0rZJTEyEvb09/Pz8pD5BQUEwMzPDwYMH73vN9cHevXvh5OSEDh06YMKECbh8+bI0Ts7bKz8/HwDQtGlTADX73UtMTISXl5d0p14ACA4ORkFBgbQX4EF067aqsHbtWjg4OKBLly6IiopCcXGxNE6u20qn02H9+vUoKipCYGAg31c3MfpxHA+C3Nxc6HQ6gx8uADg7O+PkyZMmqqp+CAgIwOrVq9GhQwdkZmZi9uzZ6NmzJ06cOAGtVgulUgl7e3uDaZydnaHVak1TcD1Rsf5Vvacqxmm1Wjg5ORmMb9SoEZo2bSrL7ffEE0/gmWeeQevWrXH27Fn85z//wYABA5CYmAhzc3PZbi+9Xo+pU6eiR48e0iMFavK7p9Vqq3z/VYx7EFW1rQBg5MiRaNWqFZo3b45jx45h+vTpOHXqFDZv3gxAftvq+PHjCAwMxPXr12FtbY0tW7bA09MTycnJfF/9P1mGIaregAEDpP937doVAQEBaNWqFb799ltYWlqasDJ60AwfPlz6v5eXF7p27Yq2bdti79696N+/vwkrM61JkybhxIkTBufqUdWq21Y3n1fm5eUFV1dX9O/fH2fPnkXbtm3vd5km16FDByQnJyM/Px+bNm1CWFgYfvnlF1OXVa/I8jCZg4MDzM3NK50xn5WVBRcXFxNVVT/Z29ujffv2OHPmDFxcXFBaWoorV64Y9OF2g7T+t3tPubi4VDpBv7y8HHl5ebLffgDQpk0bODg44MyZMwDkub0mT56MH374AXv27EGLFi2k9pr87rm4uFT5/qsY96CpbltVJSAgAAAM3lty2lZKpRLt2rWDr68vYmNj4e3tjUWLFvF9dRNZhiGlUglfX18kJCRIbXq9HgkJCQgMDDRhZfXP1atXcfbsWbi6usLX1xcWFhYG2+3UqVNIT0+X/XZr3bo1XFxcDLZNQUEBDh48KG2bwMBAXLlyBUlJSVKfn3/+GXq9XvqwlrOMjAxcvnwZrq6uAOS1vYQQmDx5MrZs2YKff/4ZrVu3Nhhfk9+9wMBAHD9+3CBA7tq1C7a2tvD09Lw/K3If3GlbVSU5ORkADN5bcthW1dHr9SgpKeH76mamPoPbVNavXy9UKpVYvXq1SElJES+++KKwt7c3OGNejl577TWxd+9ekZaWJvbv3y+CgoKEg4ODyM7OFkII8fLLL4uWLVuKn3/+WRw5ckQEBgaKwMBAE1d9fxQWForff/9d/P777wKAWLhwofj999/FhQsXhBBCzJs3T9jb24vvv/9eHDt2TAwePFi0bt1aXLt2TZrHE088Ibp16yYOHjwo9u3bJzw8PMSIESNMtUr31O22V2FhoXj99ddFYmKiSEtLE7t37xYPPfSQ8PDwENevX5fmIZftNWHCBGFnZyf27t0rMjMzpaG4uFjqc6ffvfLyctGlSxfx+OOPi+TkZBEfHy8cHR1FVFSUKVbpnrnTtjpz5oyYM2eOOHLkiEhLSxPff/+9aNOmjejVq5c0D7lsKyGEmDFjhvjll19EWlqaOHbsmJgxY4ZQKBRi586dQgi+ryrINgwJIcQnn3wiWrZsKZRKpfD39xe//fabqUsyuWHDhglXV1ehVCqFm5ubGDZsmDhz5ow0/tq1a2LixImiSZMmwsrKSjz99NMiMzPThBXfP3v27BEAKg1hYWFCiBuX18+cOVM4OzsLlUol+vfvL06dOmUwj8uXL4sRI0YIa2trYWtrK8LDw0VhYaEJ1ubeu932Ki4uFo8//rhwdHQUFhYWolWrViIiIqLSHyNy2V5VbScAYtWqVVKfmvzunT9/XgwYMEBYWloKBwcH8dprr4mysrL7vDb31p22VXp6uujVq5do2rSpUKlUol27duKNN94Q+fn5BvORw7YSQoixY8eKVq1aCaVSKRwdHUX//v2lICQE31cVFEIIcf/2QxERERHVL7I8Z4iIiIioAsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERyRrDEBEREckawxARERHJGsMQERERydr/AVjBJNpkwCcMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code plot loss and accuracy\n",
    "def plotloss_acc(train_history,acclim,losslim):\n",
    "  fig=plt.figure()\n",
    "  ax1=fig.gca()\n",
    "  ax1.set_title(\"Model accuracy and loss\")\n",
    "  ax1.plot(train_history.history['accuracy'],label=\"accuracy\",c='r')\n",
    "  ax1.plot(train_history.history['val_accuracy'],label=\"val_accuracy\",c='g')\n",
    "  ax1.set_ylim(acclim)\n",
    "  ax2=ax1.twinx()\n",
    "  ax2.plot(train_history.history['loss'],label=\"loss\",c='r',ls=\":\")\n",
    "  ax2.plot(train_history.history['val_loss'],label=\"val_loss\",c='g',ls=\"--\")\n",
    "  ax2.set_ylim(losslim)\n",
    "  ax1.legend(loc='center left')\n",
    "  ax2.legend(loc='center right')\n",
    "  plt.show()\n",
    "plotloss_acc(hist,[0.1,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
